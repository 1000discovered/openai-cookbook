{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making slides with the Assistants API and DALL-E3\n",
    "\n",
    "This notebook illustrates the use of the new [**Assistants API**](https://platform.openai.com/docs/assistants/overview) and [**DALL-E3**](https://platform.openai.com/docs/guides/images?context=node) in crafting informative and visually appealing slides. <br>\n",
    "Creating engaging slides is a pivotal aspect of many jobs, but it can be a laborious and time-consuming task. Additionally, extracting insights from data and articulating them effectively on slides can be challenging. <br><br> This cookbook recipe will demonstrate how you can utilize the new Assistants API, with GPT-Vision, and DALL-E3 to create slides for you without you having to touch Microsoft PowerPoint or Google Slides, saving you valuable time and effort!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Image\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import json\n",
    "import io\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "#Lets import some helper functions for assistants from https://cookbook.openai.com/examples/assistants_api_overview_python\n",
    "def show_json(obj):\n",
    "    display(json.loads(obj.model_dump_json()))\n",
    "\n",
    "def submit_message(assistant_id, thread, user_message,file_ids=None):\n",
    "    params = {\n",
    "        'thread_id': thread.id,\n",
    "        'role': 'user',\n",
    "        'content': user_message,\n",
    "    }\n",
    "    if file_ids:\n",
    "        params['file_ids']=file_ids\n",
    "\n",
    "    client.beta.threads.messages.create(\n",
    "        **params\n",
    ")\n",
    "    return client.beta.threads.runs.create(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant_id,\n",
    ")\n",
    "\n",
    "def get_response(thread):\n",
    "    return client.beta.threads.messages.list(thread_id=thread.id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Creating the content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this recipe, we will be creating a brief fictional presentation for the quarterly financial review of our company, NotReal Corporation. In the presentation, we want to highlight some key trends we are seeing that are affecting the profitability of our company.<br> Let's say we have the some financial data at our disposal. Let's load in the data, and take a look..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Distribution channel</th>\n",
       "      <th>Revenue ($M)</th>\n",
       "      <th>Costs ($M)</th>\n",
       "      <th>Customer count</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021</td>\n",
       "      <td>Q1</td>\n",
       "      <td>Online Sales</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.301953</td>\n",
       "      <td>150</td>\n",
       "      <td>2021 Q1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021</td>\n",
       "      <td>Q1</td>\n",
       "      <td>Direct Sales</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.380809</td>\n",
       "      <td>151</td>\n",
       "      <td>2021 Q1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021</td>\n",
       "      <td>Q1</td>\n",
       "      <td>Retail Partners</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.348246</td>\n",
       "      <td>152</td>\n",
       "      <td>2021 Q1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021</td>\n",
       "      <td>Q2</td>\n",
       "      <td>Online Sales</td>\n",
       "      <td>1.52</td>\n",
       "      <td>1.308608</td>\n",
       "      <td>152</td>\n",
       "      <td>2021 Q2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021</td>\n",
       "      <td>Q2</td>\n",
       "      <td>Direct Sales</td>\n",
       "      <td>1.52</td>\n",
       "      <td>1.413305</td>\n",
       "      <td>153</td>\n",
       "      <td>2021 Q2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year Quarter Distribution channel  Revenue ($M)  Costs ($M)  \\\n",
       "0  2021      Q1         Online Sales          1.50    1.301953   \n",
       "1  2021      Q1         Direct Sales          1.50    1.380809   \n",
       "2  2021      Q1      Retail Partners          1.50    1.348246   \n",
       "3  2021      Q2         Online Sales          1.52    1.308608   \n",
       "4  2021      Q2         Direct Sales          1.52    1.413305   \n",
       "\n",
       "   Customer count     Time  \n",
       "0             150  2021 Q1  \n",
       "1             151  2021 Q1  \n",
       "2             152  2021 Q1  \n",
       "3             152  2021 Q2  \n",
       "4             153  2021 Q2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "financial_data_path = 'data/NotRealCorp_financial_data.json'\n",
    "financial_data = pd.read_json(financial_data_path)\n",
    "financial_data.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, this data has quarterly revenue, costs and customer data across different distribution channels. Let's create an Assistant\n",
    "that can act as a personal analyst and make a nice visualization for our PowerPoint!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to upload our file so our Assistant can access it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = client.files.create(\n",
    "  file=open('data/NotRealCorp_financial_data.json',\"rb\"),\n",
    "  purpose='assistants',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we're ready to create our Assistant. We can instruct our assistant to act as a data scientist, and take any queries we give it and run the necessary code to output the proper data visualization. We can also turn on the tool of Code Interpreter, so our Assistant will be able to code. Finally, we can specifiy any files we want to use, which in this case is just the `financial_data` file we created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = client.beta.assistants.create(\n",
    "  instructions=\"You are a data scientist assistant. When given data and a query, write the proper code and create the proper visualization\",\n",
    "  model=\"gpt-4-1106-preview\",\n",
    "  tools=[{\"type\": \"code_interpreter\"}],\n",
    "  file_ids=[file.id]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a thread now, and as our first request ask the Assistant to calculate quarterly profits, and then plot the profits by distribution channel over time. The assistant will automatically calculate the profit for each quarter, and also create a new column combining quarter and year, without us having to ask for that directly. We can also specify the colors of each line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = client.beta.threads.create(\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Calculate profit (revenue minus cost) by quarter and year, and visualize as a line plot across the distribution channels, where the colors of the lines are green, light red, and light blue\",\n",
    "      \"file_ids\": [file.id]\n",
    "    }\n",
    "  ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No we can execute the run of our thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "run = client.beta.threads.runs.create(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant.id,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now start a loop that will check if the image has been created. Note: This may take a few minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant still working...\n",
      "Assistant still working...\n",
      "Assistant still working...\n",
      "Assistant still working...\n",
      "Assistant still working...\n",
      "Assistant still working...\n",
      "Assistant still working...\n",
      "Assistant still working...\n",
      "Assistant still working...\n",
      "Assistant still working...\n",
      "Assistant still working...\n",
      "Plot created!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "while True:\n",
    "    messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "    try:\n",
    "        #See if image has been created\n",
    "        messages.data[0].content[0].image_file\n",
    "        print('Plot created!')\n",
    "        break\n",
    "    except:\n",
    "        time.sleep(10)\n",
    "        print('Assistant still working...')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the messages the Assistant added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[MessageContentImageFile(image_file=ImageFile(file_id='file-UmzlAvR5fPEYizAvDAsdAeJB'), type='image_file'),\n",
       " MessageContentText(text=Text(annotations=[], value=\"The data has now been successfully loaded into a DataFrame. It contains the following columns: `Year`, `Quarter`, `Distribution channel`, `Revenue ($M)`, `Costs ($M)`, `Customer count`, and `Time`. To calculate profit by quarter and year, we need to compute the profit for each row as `Revenue ($M)` minus `Costs ($M)`, then group by `Year`, `Quarter`, and `Distribution channel` to aggregate the data.\\n\\nLet's proceed with these steps and then visualize the profit for each distribution channel as a line plot, with the lines colored green, light red, and light blue.\"), type='text'),\n",
       " MessageContentText(text=Text(annotations=[], value='The raw content of the file appears to be JSON, but the previous attempt to parse it failed because it seems that I directly tried to interpret the DataFrame column header as JSON, which was incorrect. \\n\\nSince we have confirmed that the file content seems to be JSON format, I will try again to parse the data by reading it as a raw text and then loading it into a DataFrame. This time, I will read the entire content of the file, not just the first 1024 characters.'), type='text'),\n",
       " MessageContentText(text=Text(annotations=[], value=\"The attempt to treat the data as a JSON string has failed with a JSON decode error, indicating that the data may not be in a cleanly formatted JSON structure. We need to explore a different path to correctly parse the content of the file.\\n\\nGiven that the initial attempts have not been successful, I'll now read the file as a raw text string to better understand its structure and then decide how to proceed with parsing the data into a usable format. Let's go ahead and read the file content.\"), type='text'),\n",
       " MessageContentText(text=Text(annotations=[], value=\"It seems we've encountered an issue with the data loading process. The resulting DataFrame is empty and the structure is unconventional. This might be due to an incorrect assumption about the file format or a parsing error.\\n\\nI will retry loading the data using a different approach, perhaps by specifying additional parameters or a different method, to handle possibly more complex formats like JSON or a differently structured Excel file. Let's attempt this now.\"), type='text'),\n",
       " MessageContentText(text=Text(annotations=[], value=\"Before we can calculate the profit by quarter and year and visualize it across the distribution channels, I need to examine the contents of the uploaded file to understand its structure and determine what data it contains. Let's start by loading the data and taking a look at the first few rows to assess what preprocessing steps might be necessary.\"), type='text'),\n",
       " MessageContentText(text=Text(annotations=[], value='Calculate profit (revenue minus cost) by quarter and year, and visualize as a line plot across the distribution channels, where the colors of the lines are green, light red, and light blue'), type='text')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "[message.content[0] for message in messages.data]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the last message (latest message is shown first) from the assistant contains the image file we are looking for.  We can write a quick helper function to convert our output file to a png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_file_to_png(file_id, write_path):\n",
    "    data = client.files.content(file_id)\n",
    "    data_bytes = data.read()\n",
    "    with open(write_path, \"wb\") as file:\n",
    "        file.write(data_bytes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_file_id = messages.data[0].content[0].image_file.file_id\n",
    "image_path = \"data/NotRealCorp_chart.png\"\n",
    "convert_file_to_png(plot_file_id,image_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load in the plot!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Financial data plot](data/NotRealCorp_chart.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! So, with just one sentence, we were able to have our assistant use code interpreter to\n",
    "calculate the profitability, and graph the three lineplots of the various distribution channels.<br><br>\n",
    "Now we have a nice visual for our slide, but we want some insights to go along with it. Let's use GPT-Vision to help us generate those."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generating insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get insights from our image, we simply need to add a new message to our thread. Our Assistant will know to use GPT-Vision, and can give us some concise takeaways from the visual provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Run(id='run_kMFCS9y7f0EKXkVEVX0MJEAC', assistant_id='asst_7g0ZZvr42G9vxVBHyNCy2rIn', cancelled_at=None, completed_at=None, created_at=1701663813, expires_at=1701664413, failed_at=None, file_ids=['file-1JMqJZGth54cPsMKdwuCgmYG'], instructions='You are a data scientist assistant. When given data and a query, write the proper code and create the proper visualization', last_error=None, metadata={}, model='gpt-4-1106-preview', object='thread.run', required_action=None, started_at=None, status='queued', thread_id='thread_jpiHVuCY2Vr0wPXeLVk9zExB', tools=[ToolAssistantToolsCode(type='code_interpreter')])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_message(assistant.id,thread,\"Give me two medium length sentences (~20-30 words per sentence) of the \\\n",
    "      most important insights from the plot you just created.\\\n",
    "             These will be used for a slide deck, and they should be about the\\\n",
    "                     'so what' behind the data.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, once the run has completed, we can get the latest message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The line plot indicates that \"Online Sales\" consistently outperformed other channels in profitability, showing a steady upward trend throughout the observed quarters. \"Direct Sales\" and \"Retail Partners\" exhibited more variability, with \"Retail Partners\" experiencing a notable profit increase in later periods.\n"
     ]
    }
   ],
   "source": [
    "# Hard coded wait for a response, as the assistant may iterate on the bullets.\n",
    "time.sleep(10)\n",
    "response = get_response(thread)\n",
    "bullet_points = response.data[0].content[0].text.value\n",
    "print(bullet_points)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool! Now we have some two insights to accompany our plot. Now let's get a compelling title for the slide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Run(id='run_L64nABxuBXpu2KqgfT7yhUBA', assistant_id='asst_7g0ZZvr42G9vxVBHyNCy2rIn', cancelled_at=None, completed_at=None, created_at=1701663831, expires_at=1701664431, failed_at=None, file_ids=['file-1JMqJZGth54cPsMKdwuCgmYG'], instructions='You are a data scientist assistant. When given data and a query, write the proper code and create the proper visualization', last_error=None, metadata={}, model='gpt-4-1106-preview', object='thread.run', required_action=None, started_at=None, status='queued', thread_id='thread_jpiHVuCY2Vr0wPXeLVk9zExB', tools=[ToolAssistantToolsCode(type='code_interpreter')])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_message(assistant.id,thread,\"Given the plot and bullet points you created,\\\n",
    " come up with a very brief title for a slide. It should reflect just the main insights you came up with.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the title is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Online Sales Lead Profit Growth Across Channels\"\n"
     ]
    }
   ],
   "source": [
    "#Wait as assistant may take a few steps\n",
    "time.sleep(10)\n",
    "response = get_response(thread)\n",
    "title = response.data[0].content[0].text.value\n",
    "print(title)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. DALL-E3 title image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice, now we have a title, a plot and two bullet points. We're almost ready to put this all on a slide, but as a final step, let's have DALL-E3 come up with an image to use as the title slide of the presentation. <br><br>\n",
    "*Note:* DALL-E3 is not yet available within the assistants API but is coming soon! <br> <br>\n",
    "We'll feed in a brief description of our company (NotRealCorp) and have DALL-E3 do the rest!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_summary = \"NotReal Corp is a prominent hardware company that manufactures and sells processors, graphics cards and other essential computer hardware.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.images.generate(\n",
    "  model='dall-e-3',\n",
    "  prompt=f\"given this company summary {company_summary}, create an inspirational \\\n",
    "    photo showing the growth and path forward. This will be used at a quarterly\\\n",
    "       financial planning meeting\",\n",
    "       size=\"1024x1024\",\n",
    "       quality=\"hd\",\n",
    "       n=1\n",
    ")\n",
    "image_url = response.data[0].url\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at our image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image](data/dalle_img.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool, now we can add this image to our thread, and ask the Assistant API to write the code to create our slide!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we can save the image locally, then upload it using the `File` upload endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dalle_img_path = 'data/dalle_image.png'\n",
    "img = requests.get(image_url)\n",
    "\n",
    "#Save locally\n",
    "with open(dalle_img_path,'wb') as file:\n",
    "  file.write(img.content)\n",
    "\n",
    "#Upload\n",
    "file = client.files.create(\n",
    "  file=open(dalle_img_path, \"rb\"),\n",
    "  purpose='assistants'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can simply ask the Assistant API to create a PowerPoint using the content it has helped us generate so far. We generated the title DALL-E3 image separately, so we will explicitly upload the file, but otherwise will ask the Assistant to use the relevant data to generate two slides in whatever format we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Run(id='run_kPvYu6oKwMVmwocMRDqTm5IA', assistant_id='asst_7g0ZZvr42G9vxVBHyNCy2rIn', cancelled_at=None, completed_at=None, created_at=1701663863, expires_at=1701664463, failed_at=None, file_ids=['file-1JMqJZGth54cPsMKdwuCgmYG'], instructions='You are a data scientist assistant. When given data and a query, write the proper code and create the proper visualization', last_error=None, metadata={}, model='gpt-4-1106-preview', object='thread.run', required_action=None, started_at=None, status='queued', thread_id='thread_jpiHVuCY2Vr0wPXeLVk9zExB', tools=[ToolAssistantToolsCode(type='code_interpreter')])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_message(assistant.id,thread,\"Output a pptx slide deck with two slides as follows:\\\n",
    "               MAKE SURE the first slide is titled 'NotRealCorp: Quarterly financial planning meeting, Q3 2023' at the top of the screen, with large heading font size. The image included should be large but positioned BELOW the text. IMPORTANT: Do not have the title text and images overlap. ALL SLIDES should have the top third JUST for Titles. Make sure the image is not taking up the whole screen, so the reader can see the entire title. The second\\\n",
    "               slide should include the image of the line plot you generated earlier, this should be the only image file you have made from earlier in the conversation, which shows profits by distribution channel on the LHS of the screen, and include the insights you then provided on that plot on the RHS of the screen, in bullet form.\\\n",
    "              The insights should be under a larger, teal blue heading that says 'Key Insights:'. The image and the insights should CENTERED in the page. Make sure the code for the slides have a black background and white text, and are sleek and clean.\\\n",
    "               MAKE SURE the title of the second slide is the title you generated earlier, and is larger title text at the top of the screen, and that the second slide contains the image of the line plot you generated earlier.\\\n",
    "               MAKE SURE the slide titles are all in one row, one line, and take up the entire width of the page.\\\n",
    "               Check your work as you go, and make sure you are following all initial instructions as you move take each step.\",\n",
    "              file_ids=[file.id]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant still working on PPTX...\n",
      "Assistant still working on PPTX...\n",
      "Assistant still working on PPTX...\n",
      "Assistant still working on PPTX...\n",
      "Assistant still working on PPTX...\n",
      "Assistant still working on PPTX...\n",
      "Assistant still working on PPTX...\n",
      "Assistant still working on PPTX...\n",
      "Successfully retrieved pptx_id: file-GRuk8av2xSXtRdk5cGX1vcDj\n"
     ]
    }
   ],
   "source": [
    "#May take 1-3 mins\n",
    "while True:\n",
    "    try:\n",
    "        response = get_response(thread)\n",
    "        pptx_id = response.data[0].content[0].text.annotations[0].file_path.file_id\n",
    "        print(\"Successfully retrieved pptx_id:\", pptx_id)  # Add this line\n",
    "        break\n",
    "    except Exception as e:  # Catch the exception and print it\n",
    "        print(\"Assistant still working on PPTX...\")\n",
    "        time.sleep(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppt_file= client.files.content(pptx_id)\n",
    "file_obj = io.BytesIO(ppt_file.read())\n",
    "with open(\"data/ppt_generated.pptx\", \"wb\") as f:\n",
    "    f.write(file_obj.getbuffer())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Creating the slides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have a PPTX file saved with all of our created content!. <br>\n",
    "We don't have a `seed` parameter yet in the Assistants API, so the DALL-E3 image and wordings will be slightly different from what you see when you run this notebook, due to the non-deterministic quality of LLMs, but the outputs should be directionally the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the screenshots of the .pptx we just created using JUST the assistants API and DALL-E3, we have the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Title slide](data/title_slide.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And for the data slide, we have:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Data slide](data/data_viz_slide.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Woo! While these slides could use some small formatting tweaks, we have made some great content, using just the Assistants API, GPT-4, GPT-Vision, and DALL-E3. Hopefully this helps make the slide creation process a bit easier, and provides a glimpse into how helpful the Assistants API can be!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
