{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Voice Translation of Audio files \n",
    "\n",
    "Ever wanted to translate a podcast into your native language? In this cookbook we will walk through steps to dub an audio podcast from English to Hindi.   \n",
    "\n",
    "The overall steps in the process are: \n",
    "1. Transcribe the audio file into text with Whisper \n",
    "2. Translate the text in language of your choice with GPT \n",
    "3. Convert the translated text to audio with tts (text-to-speech) \n",
    "4. Translation benchmarking (BLEU or ROUGE) \n"
   ],
   "id": "4265ef1326248608"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Step 1: Transcribe the audio file into text with Whisper \n",
    "\n"
   ],
   "id": "d84f1356379946f6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T18:52:35.352410Z",
     "start_time": "2024-09-03T18:52:25.834003Z"
    }
   },
   "cell_type": "code",
   "source": [
    "audio_file = \"../gpt4o/data/keynote_recap.mp3\"\n",
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "audio_file= open(audio_file, \"rb\")\n",
    "transcription = client.audio.transcriptions.create(\n",
    "  model=\"whisper-1\",  \n",
    "  file=audio_file\n",
    ")\n",
    "print(transcription.text)\n",
    "\n"
   ],
   "id": "7d10f34bb10ab45",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to our first-ever OpenAI Dev Day. Today, we are launching a new model, GPT-4 Turbo. GPT-4 Turbo supports up to 128,000 tokens of context. We have a new feature called JSON mode, which ensures that the model will respond with valid JSON. You can now call many functions at once, and it'll do better at following instructions in general. You want these models to be able to access better knowledge about the world. So do we. So we're launching retrieval in the platform. You can bring knowledge from outside documents or databases into whatever you're building. GPT-4 Turbo has knowledge about the world up to April of 2023, and we will continue to improve that over time. Dolly 3, GPT-4 Turbo with Vision, and the new Text-to-Speech model are all going into the API today. Today, we're launching a new program called Custom Models. With Custom Models, our researchers will work closely with the company to help them make a great custom model, especially for them and their use case using our tools, higher rate limits. We're doubling the tokens per minute for all of our established GPT-4 customers so that it's easier to do more, and you'll be able to request changes to further rate limits and quotas directly in your API account settings. And GPT-4 Turbo is considerably cheaper than GPT-4 by a factor of 3x for prompt tokens and 2x for completion tokens, starting today. We're thrilled to introduce GPTs. GPTs are tailored versions of chat GPT for a specific purpose. And because they combine instructions, expanded knowledge, and actions, they can be more helpful to you. They can work better in many contexts, and they can give you better control. We know that many people who want to build a GPT don't know how to code. We've made it so that you can program the GPT just by having a conversation. You can make private GPTs. You can share your creations publicly with a link for anyone to use. Or if you're on chat GPT Enterprise, you can make GPTs just for your company. And later this month, we're going to launch the GPT Store. So those are the GPTs, and we can't wait to see what you'll build. We're bringing the same concept to the API. The Assistance API includes persistent threads, so they don't have to figure out how to deal with long conversation history, built-in retrieval, code interpreter, a working Python interpreter in a sandbox environment, and of course, the improved function calling. As intelligence gets integrated everywhere, we will all have superpowers on demand. We're excited to see what you all will do with this technology, and to discover the new future that we're all going to architect together. We hope that you'll come back next year. What we launched today is going to look very quaint relative to what we're busy creating for you now. Thank you for all that you do. Thanks for coming here today.\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T18:47:41.234830Z",
     "start_time": "2024-09-03T18:47:28.421776Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are an assistant that translates text from English to Hindi. User will provide content for you to translate. You may keep certain words in English for which a direct translation doesn't exist. Some words to keep in English include - Turbo, OpenAI, token, GPT, Dall-e, Python\"},\n",
    "    {\"role\": \"user\", \"content\": transcription.text},\n",
    "  ]\n",
    ")\n",
    "\n",
    "message = response.choices[0].message.content\n",
    "\n",
    "print(message)"
   ],
   "id": "330baa9a6e55530c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "हमारे पहले OpenAI Dev Day में आपका स्वागत है। आज, हम एक नया मॉडल, GPT-4 Turbo लॉन्च कर रहे हैं। GPT-4 Turbo 128,000 tokens तक के context का समर्थन करता है। हमारे पास JSON mode नाम का एक नया फीचर है, जो सुनिश्चित करता है कि मॉडल वैध JSON के साथ प्रतिक्रिया देगा। अब आप कई functions को एक साथ कॉल कर सकते हैं, और यह सामान्य रूप से निर्देशों का पालन करने में बेहतर करेगा। आप चाहते हैं कि ये मॉडल दुनिया के बारे में बेहतर ज्ञान प्राप्त कर सकें। हम भी ऐसा ही चाहते हैं। इसलिए हम प्लेटफॉर्म में retrieval लॉन्च कर रहे हैं। आप बाहरी दस्तावेजों या डेटाबेस से ज्ञान को अपने निर्माण में ला सकते हैं। GPT-4 Turbo के पास अप्रैल 2023 तक की दुनिया के बारे में ज्ञान है, और हम इसे समय के साथ सुधारते रहेंगे। Dolly 3, GPT-4 Turbo with Vision, और नया Text-to-Speech मॉडल सभी आज API में जा रहे हैं। आज, हम Custom Models नामक एक नया प्रोग्राम लॉन्च कर रहे हैं। Custom Models के साथ, हमारे शोधकर्ता कंपनी के साथ मिलकर काम करेंगे ताकि वे उनके विशेष उपयोग के मामले के लिए एक महान कस्टम मॉडल बना सकें, जो हमारे टूल्स और उच्च दर सीमा का उपयोग करके चलता है। हम अपने सभी स्थापित GPT-4 ग्राहकों के लिए प्रति मिनट tokens की गिनती को दोगुना कर रहे हैं ताकि और अधिक करना आसान हो जाए, और आप सीधे अपने API खाता सेटिंग्स में आगे की दर सीमा और कोटा अनुरोध कर सकेंगे। GPT-4 Turbo, GPT-4 की तुलना में 3x सस्ता है prompt tokens के लिए और 2x सस्ता है completion tokens के लिए, आज से शुरू हो रहा है। हम GPTs को पेश करने के लिए रोमांचित हैं। GPTs चैट GPT के विशेष उद्देश्य के लिए अनुकूलित संस्करण हैं। और क्योंकि वे निर्देश, विस्तारित ज्ञान और कार्यों को जोड़ते हैं, वे आपके लिए अधिक सहायक हो सकते हैं। वे कई संदर्भों में बेहतर काम कर सकते हैं, और वे आपको बेहतर नियंत्रण दे सकते हैं। हम जानते हैं कि बहुत से लोग जो GPT बनाना चाहते हैं, वे कोड करना नहीं जानते। हमने इसे इस तरह से बनाया है कि आप बस एक वार्तालाप करके GPT को प्रोग्राम कर सकते हैं। आप private GPTs बना सकते हैं। आप एक लिंक के साथ अपनी कृतियों को सार्वजनिक रूप से साझा कर सकते हैं ताकि कोई भी उनका उपयोग कर सके। या यदि आप chat GPT Enterprise पर हैं, तो आप केवल अपनी कंपनी के लिए GPTs बना सकते हैं। और इस महीने के अंत में, हम GPT Store लॉन्च करने जा रहे हैं। तो ये हैं GPTs, और हम यह देखने के लिए इंतजार नहीं कर सकते कि आप क्या बनाएंगे। हम API में भी इसी अवधारणा को ला रहे हैं। Assistance API में persistent threads शामिल हैं, इसलिए वे लंबी वार्तालाप इतिहास से निपटने के तरीके का पता नहीं लगाना पड़ता है, built-in retrieval, code interpreter, एक sandbox environment में काम कर रहा Python interpreter, और निश्चित रूप से, सुधरा हुआ function calling। जैसे-जैसे बुद्धिमत्ता हर जगह एकीकृत हो जाती है, हम सभी के पास मांग पर सुपरपावर्स होंगे। हम इस तकनीक के साथ आप सभी क्या करेंगे यह देखने के लिए उत्साहित हैं, और उस नए भविष्य की खोज करने के लिए जो हम सभी एक साथ तैयार करने जा रहे हैं। हम आशा करते हैं कि आप अगले साल फिर से आएंगे। \n",
      "आज हमने जो लॉन्च किया है वह उस समय की तुलना में बहुत साधारण लगेगा जो हम अभी आपके लिए बना रहे हैं। आप जो कुछ भी करते हैं उसके लिए धन्यवाद। \n",
      "आज यहां आने के लिए धन्यवाद।\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T20:08:27.886265Z",
     "start_time": "2024-08-30T20:07:56.095698Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.audio.speech.create(\n",
    "    model=\"tts-1\",\n",
    "    voice=\"alloy\",\n",
    "    input=message,\n",
    ")\n",
    "\n",
    "response.stream_to_file(\"output.mp3\")"
   ],
   "id": "dc7922ea7f33b4d3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jk/xl1ppdk94637355tx59m0kph0000gp/T/ipykernel_9722/2703525150.py:11: DeprecationWarning: Due to a bug, this method doesn't actually stream the response content, `.with_streaming_response.method()` should be used instead\n",
      "  response.stream_to_file(\"output.mp3\")\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "5a380d3df383d1e4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-30T20:12:00.525584Z",
     "start_time": "2024-08-30T20:08:30.434888Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from playsound import playsound\n",
    "\n",
    "playsound(\"output.mp3\")"
   ],
   "id": "e5545d55bf8be52a",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# Checking the quality of translation \n",
   "id": "d839b0cca9b8d22b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
