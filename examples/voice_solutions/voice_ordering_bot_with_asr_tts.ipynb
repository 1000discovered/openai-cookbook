{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Voice Chatbot with ASR (Automatic Speech Recognition)\n",
    "\n",
    "In this cookbook, we will walk through the process of creating a simple sales chatbot with automatic speech recognition (ASR) and text-to-speech (TTS) capabilities. We'll use a GPT model via the Chat Completions API to drive the conversation with the user. At the end of the interaction, the chatbot will present an order cart containing the items the user wishes to purchase.\n",
    "\n",
    "Voice chatbots based on ASR/TTS can introduce latency due to the speech-to-text and text-to-speech conversion processes. We will explore strategies to minimize this lag to ensure a better conversational flow.\n",
    "\n",
    "Creating an ASR/TTS-based voice chatbot is a three-step process, as outlined below:\n",
    "\n",
    "**1. Set Up the GPT Model (Text-to-Text Modality)**  \n",
    "Initialize the GPT model with system prompts that define the goal of the conversation, guiding the chatbot's responses toward assisting with sales order placement. The prompts can be set up for a multi-assistant system, where one assistant drives the conversation with the customer and another assistant manages the cart in parallel. Also, set up tools for assistants to use when asking for human help or interacting with each other (such as cart pricing).\n",
    "\n",
    "**2. Develop Audio Modules for ASR (Automatic Speech Recognition) and TTS (Text-To-Speech)**  \n",
    "Create an audio interface that listens to the user, records their speech, and forwards the audio data to the ASR solution (such as Whisper) to transcribe it to text. Implement a **VAD (Voice Activity Detection) module** for a **handsfree operation**. This module detects input audio from user and segments the audio at silence intervals to send to Whisper model for transcription. Keep VAD (Voice Activity Detection) module parameters (threshold of audio amplitude that qualifies as silence, and the duration of silent chunks) configurable, so they can be adjusted based on the environment. Set up a TTS function that, given an input text, converts the text to audio and relays it back to the user. You can pre-record common phrases to reduce lag.\n",
    "\n",
    "**3. Create a conversation loop and manage order cart**  \n",
    "Implement a conversation loop where the agent listens to the user and responds back, continuing until an event occurs that breaks the loop, such as a request to speak with a human or another indication of the end of the conversation.\n",
    "\n",
    "\n",
    "Overarching solution architecture is as follows:   \n",
    "![ASR/TTS](./images/asr-text-to-speech.png)"
   ],
   "id": "1da75457ef55742c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "For the purposes of this cookbook, we will use an example of an office stationery ordering bot. You can interact with the bot to order general-purpose office products such as pencils, pens, paper clips, writing pads, printing paper, and envelopes.\n",
    "\n",
    "The key challenges we want to address are:\n",
    "\n",
    "1. Ensure customers can only order items that are available.\n",
    "2. Escalate to a human in the loop if the customer requests help or engages in non-order-related conversation.\n",
    "3. Provide an accurate summary of the order with prices to the customer.\n",
    "4. Minimize the lag in the conversation \n",
    "\n",
    "\n",
    "Before we get started, make sure you have the following libraries installed: `pyaudio`, `numpy`, `openai`, `playsound`, and that you have configured your OpenAI API key as an environment variable."
   ],
   "id": "9a2d40790873cafc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 1. Set Up the GPT Model (Text-to-Text Modality)\n",
    "\n",
    "First step is to set the foundation for the GPT model to operate effectively as a sales chatbot within the office stationery domain. By carefully crafting the prompts and defining the functions, we ensure that the bot can handle customer interactions smoothly, maintain the flow of conversation, and provide accurate assistance aligned with the objectives of our project.\n",
    "\n",
    "We will initiate a Sales Bot prompt `SALES_BOT_PROMPT` that would drive the interaction with the user, and a `SALES_CART_PROMPT` prompt that would manage the cart. Note that the list of items available for sale are provide as a list of JSON objects `office_stationery_items`. This helps the sales bot and sales cart assistant to understand the available items, and repond the user accordingly.  \n"
   ],
   "id": "5ca789980db6ef46"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T16:27:15.281729Z",
     "start_time": "2024-09-06T16:27:15.274856Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "\n",
    "# Creates a list of dictionaries, where each dictionary represents an office stationery item available for purchase.\n",
    "office_stationery_items = [\n",
    "    {\"item-id\": \"0001\", \"item-name\": \"pencil\", \"item-price\": \"$0.50\"},\n",
    "    {\"item-id\": \"0002\", \"item-name\": \"pen\", \"item-price\": \"$1.00\"},\n",
    "    {\"item-id\": \"0003\", \"item-name\": \"clip\", \"item-price\": \"$0.05\"},\n",
    "    {\"item-id\": \"0004\", \"item-name\": \"writing pad\", \"item-price\": \"$2.00\"},\n",
    "    {\"item-id\": \"0005\", \"item-name\": \"printing paper\", \"item-price\": \"$5.00\"},\n",
    "    {\"item-id\": \"0006\", \"item-name\": \"envelope\", \"item-price\": \"$0.10\"}\n",
    "]\n",
    "\n",
    "# Defines the system prompt that instructs the GPT model on how to behave during the conversation.\n",
    "SALES_BOT_PROMPT = f\"\"\"You are a office stationery sales bot. The customer will ask to buy one of the following items. Follow the rules below: \n",
    "1. Be succinct in your responses up to 10 words or less if possible.  \n",
    "2. If the customer asks for an item that is not available, you should let the customer know that item is not available.\n",
    "3. Once the customer has placed an order, reply with ANYTHING ELSE\n",
    "4. If the customer wants to chat with a human, call the function  'get_human_help'\n",
    "5. If the customer discusses any other topic, other than ordering office stationery, call the function 'get_human_help'\n",
    "6. When the order is final, call the function `get_order_details` and let the customer know the price.\n",
    "<LIST OF ITEMS>\n",
    "{office_stationery_items}\n",
    "</LIST OF ITEMS>  \n",
    "\"\"\"\n",
    "\n",
    "# Provides a separate prompt to guide the bot in generating the final order cart\n",
    "# An example is provided to illustrate the desired output format, ensuring consistency and accuracy in the bot's response\n",
    "# This could be further enhanced by structured output, but one shot example is sufficient in this context \n",
    "SALES_CART_PROMPT = f\"\"\"You are an office stationery sales bot, that will generate a cart based on a conversation between a user and an agent. The list of items available for purchase is provided below. Output the cart in JSON format. Include quantity and total price of the order. \n",
    "\n",
    "<LIST OF ITEMS>\n",
    "{office_stationery_items}\n",
    "</LIST OF ITEMS> \n",
    "\n",
    "<EXAMPLE OF A CART> \n",
    "{{\n",
    "  \"cart\": [\n",
    "    {{\n",
    "      \"item-id\": \"0001\",\n",
    "      \"item-name\": \"pencil\",\n",
    "      \"quantity\": 4,\n",
    "      \"item-price\": \"$0.50\",\n",
    "      \"total-item-price\": \"$2.00\"\n",
    "    }}\n",
    "  ],\n",
    "  \"total-price\": \"$2.00\"\n",
    "}}\n",
    "</EXAMPLE OF A CART> \n",
    "\"\"\"\n",
    "\n",
    "# Defines functions that the bot can \"call\" during the conversation to handle specific situations such as to get order details and get human help \n",
    "TOOLS = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_order_details\",\n",
    "            \"description\": \"Use this function once the customer has finished ordering to get the order price.\"\n",
    "        }\n",
    "    }, \n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_human_help\",\n",
    "            \"description\": \"Use this function if customer discusses topics other than the order or wants to speak with a human.\"\n",
    "        }\n",
    "    }]\n",
    "\n",
    "# Initialize the prompt for sales agent \n",
    "sales_agent_prompt = [{\"role\": \"system\", \"content\": SALES_BOT_PROMPT}]\n",
    "\n",
    "# Initialize the prompt for pricing agent \n",
    "pricing_agent_prompt = [{\"role\": \"system\", \"content\": SALES_CART_PROMPT}]"
   ],
   "id": "ca401ffc1d9003c0",
   "outputs": [],
   "execution_count": 71
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2. Develop Audio Modules for ASR (Automatic Speech Recognition) and TTS (text-to-speech)\n",
    "\n",
    "The following Python code implements an interactive voice agent that facilitates customer interactions for ordering office stationery.  \n",
    " \n",
    "The `listen()` function implements the **VAD (Voice Activity Detection) module** using `PyAudio` that streams the audio in `frames_per_buffer` defined as `CHUNK`. Each `CHUNK` is `1024` frames in the audio buffer. Function `is_silent(input_data)` determines if the audio data is below the `SILENCE_THRESHOLD` to classify the audio chunk as silent. This can help filter out low noise in the environment such as breathing sounds. If there are consecutive `50` `SILENT_CHUNKS`  as defined in the code below, the function interprets it as the customer has finished speaking, and saves the audio to a WAV file. To qualify as valid user input, the user must have spoken something which is determined using `SPOKEN_CHUNKS`. Once the **VAD (Voice Activity Detection) module** determines the user input is valid, and user has finished speaking, the audio is sent to OpenAI's Whisper model for **ASR (Automatic Speech Recognition)**, and transcription in English returned as part of the function call.  \n",
    "\n",
    "Variables `SPOKEN_CHUNKS`, `SILENCE_THRESHOLD` and `SILENT_CHUNKS` can be adjusted based on the environment and type of use case to segment the input audio. \n",
    "\n",
    "The `speak(agent_message)` function takes the agent's text response, converts it into spoken audio using OpenAI's text-to-speech model, saves it as a WAV file, and plays it back to the customer. Overall, the code enables a conversational interface by integrating speech recognition and synthesis. [Note that in this implementation audio cannot be interrupted once the function starts speaking. The user must wait for its turn to speak.] \n",
    "\n",
    "To reduce the lag, we have pre-recorded sound snippets and stored them under `sounds` folder. If agent response is one of these pre-recorded phrases we can play them instantaneously, reducing the perceived lag. \n"
   ],
   "id": "6414f3bab57b040b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T16:40:05.474993Z",
     "start_time": "2024-09-06T16:40:05.441152Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pyaudio\n",
    "import numpy as np\n",
    "import wave\n",
    "from openai import OpenAI\n",
    "from playsound import playsound\n",
    "\n",
    "CHUNK = 1024  # CHUNK sets the number of frames per buffer.\n",
    "FORMAT = pyaudio.paInt16  # FORMAT specifies the sample format (16-bit in this case).\n",
    "CHANNELS = 1  # CHANNELS sets the number of audio channels: 1 for mono, 2 for stereo\n",
    "RATE = 44100  # RATE sets the sample rate to 44100 Hz\n",
    "SILENCE_THRESHOLD = 20  # Adjust this threshold based on your environment\n",
    "SILENT_CHUNKS = 50  # Number of chunks of silence to trigger stop\n",
    "SPOKEN_CHUNKS = 50  # Number of spoken chunks to have a valid response from the user\n",
    "\n",
    "oai_client = OpenAI()\n",
    "\n",
    "\n",
    "# List of pre-recorded messages \n",
    "initial_message = \"What would you like to order?\"\n",
    "human_help_message = \"Let me get you a human to help!\"\n",
    "finalize_order = \"Thank you for your order, let me calculate the total price.\"\n",
    "anything_else = \"Anything else\"\n",
    "\n",
    "\n",
    "def listen():\n",
    "    \"\"\"Listen to the customer. Return the text from the speech\"\"\"\n",
    "    print(\"Agent listening ...\")\n",
    "\n",
    "    def is_silent(input_data):\n",
    "        \"\"\"Check if the given data chunk is silent.\"\"\"\n",
    "        audio_data = np.frombuffer(input_data, dtype=np.int16)\n",
    "        return np.abs(audio_data).mean() < SILENCE_THRESHOLD\n",
    "\n",
    "    output = \"user_response.wav\"\n",
    "    with wave.open(output, 'wb') as wf:\n",
    "        p = pyaudio.PyAudio()\n",
    "        wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "        wf.setnchannels(CHANNELS)\n",
    "        wf.setframerate(RATE)\n",
    "\n",
    "        stream = p.open(format=FORMAT,\n",
    "                        channels=CHANNELS,\n",
    "                        rate=RATE,\n",
    "                        input=True,\n",
    "                        frames_per_buffer=CHUNK)\n",
    "\n",
    "        # print(\"* recording\")\n",
    "        frames = []\n",
    "        silent_chunks = 0\n",
    "        speech_chunks = 0\n",
    "\n",
    "        while True:\n",
    "            data = stream.read(CHUNK)\n",
    "            frames.append(data)\n",
    "\n",
    "            if is_silent(data):\n",
    "                silent_chunks += 1\n",
    "            else:\n",
    "                silent_chunks = 0\n",
    "                speech_chunks += 1\n",
    "\n",
    "            if silent_chunks > SILENT_CHUNKS and speech_chunks > SPOKEN_CHUNKS:\n",
    "                break\n",
    "\n",
    "        print(\"* done listening\")\n",
    "        stream.stop_stream()\n",
    "        stream.close()\n",
    "        p.terminate()\n",
    "        wf.writeframes(b''.join(frames))\n",
    "\n",
    "        # Upload the recorded audio file to OpenAI whisper-1 model for transcription\n",
    "        audio_file = open(output, \"rb\")\n",
    "        transcription = oai_client.audio.transcriptions.create(\n",
    "            model=\"whisper-1\",\n",
    "            file=audio_file,\n",
    "            prompt=\"This is a customer trying to order office stationery\"\n",
    "        )\n",
    "\n",
    "        return transcription.text\n",
    "\n",
    "\n",
    "def speak(agent_message):\n",
    "    # Common phrases can be pre-recorded to reduce the lag \n",
    "    if agent_message.lower() == initial_message.lower():\n",
    "        print(\"Agent speaking ... (pre-recorded audio)\")\n",
    "        playsound(\"./sounds/initial_message.wav\")\n",
    "    \n",
    "    elif agent_message.lower() == human_help_message.lower(): \n",
    "        print(\"Agent speaking ... (pre-recorded audio)\")\n",
    "        playsound(\"./sounds/human_help_message.wav\")\n",
    "        \n",
    "    elif agent_message.lower() == finalize_order.lower(): \n",
    "        print(\"Agent speaking ... (pre-recorded audio)\")\n",
    "        playsound(\"./sounds/finalize_order.wav\")\n",
    "    \n",
    "    elif agent_message.lower() == anything_else.lower():\n",
    "        print(\"Agent speaking ... (pre-recorded audio)\")\n",
    "        playsound(\"./sounds/anything_else.wav\")\n",
    "    \n",
    "    else:\n",
    "        print(\"Agent speaking ...(new audio file generated)\")\n",
    "        # Convert text to speech\n",
    "        agent_voice_response = oai_client.audio.speech.create(\n",
    "            model=\"tts-1\",\n",
    "            voice=\"nova\",\n",
    "            input=agent_message\n",
    "        )\n",
    "        # Save to the file\n",
    "        agent_voice_response.write_to_file(\"agent_response.wav\")\n",
    "\n",
    "        # play the audio file\n",
    "        playsound(\"agent_response.wav\")\n",
    "        "
   ],
   "id": "8a6432a6a8bf1055",
   "outputs": [],
   "execution_count": 77
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 3. Create a conversation loop and manage order cart  \n",
    "\n",
    "The code below utilizes `listen()` and `speak()` functions in tandem to handle ASR (Automatic Speech Recognition) with VAD (Voice Activity Detection), and TTS (Text-To-Speech) as discussed in previous section. This loop enables **handsfree voice-based communication** with the application.\n",
    " \n",
    "The Application initiates a conversation with a user asking what they would like to order with `speak()` function, then continuously listens to the user's input using the `listen()` function. The voice conversation is managed through a sales agent that processes each user input and provides a response. The conversation is maintained in a message dictionary `messages_dictionary`, which is the log of entire interaction. \n",
    "\n",
    "The sales agent manages the response to user's input. It is guided by the `SALES_BOT_PROMPT`, which includes the list of available items, ensuring the agent only processes orders for items in stock. If the response generated by the sales agent response involves a tool call, such as finalize the order by getting order details or get a human for help, the loop breaks, signaling the end of the interaction.    \n",
    "\n",
    "The cart management agent is guided by the `SALES_CART_PROMPT` and generates a detailed cart in JSON format, including item quantities and total prices, ensuring the user receives an accurate summary of their order. Both agents receive the same item inventory in JSON format, and the same messages dictionary of the conversation. In production applications, cart management agent can be run in parallel as an asynchronous process to reduce the lag.  \n",
    "\n",
    "It is also a good idea to convert the numeric dollar price (e.g., $3.00) into spoken description of the amount (e.g., 3 dollars and 0 cents) for a more natural sounding response. This is accomplished by the `convert_to_words` function below. "
   ],
   "id": "2c1a6928918c674e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T16:40:39.232786Z",
     "start_time": "2024-09-06T16:40:06.704932Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Helper Util to convert the $ amount into spoken description for a natural sounding response  \n",
    "def convert_to_words(amount_str):\n",
    "    try: \n",
    "        # Remove the dollar sign and convert the string to a float\n",
    "        amount = float(amount_str.replace('$', '').strip())\n",
    "    \n",
    "        # Separate the dollar and cent parts\n",
    "        dollars = int(amount)\n",
    "        cents = int(round((amount - dollars) * 100))\n",
    "    \n",
    "        # Convert dollars and cents to words\n",
    "        dollar_word = f\"{dollars} dollar{'s' if dollars != 1 else ''}\"\n",
    "        cent_word = f\"{cents} cent{'s' if cents != 1 else ''}\"\n",
    "    \n",
    "        # Construct the final string\n",
    "        return f\"{dollar_word} and {cent_word}\"\n",
    "    except ValueError: \n",
    "        print(\"Unable to convert to spoken description\")\n",
    "        return amount_str\n",
    "    \n",
    "\n",
    "# Set the messages dictionary with initial welcome message to the customer\n",
    "messages_dictionary = [{\n",
    "    \"role\": \"assistant\",\n",
    "    \"content\": initial_message\n",
    "}] \n",
    "\n",
    "# Set cart to empty \n",
    "cart = [] \n",
    "\n",
    "# Initiate the conversation with the user \n",
    "speak(initial_message)\n",
    "\n",
    "\n",
    "# Loop until the user has completed the order or asks for human help \n",
    "while True:\n",
    "    # listen to the user input \n",
    "    user_input = listen()\n",
    "\n",
    "    # Append the message to messages dictionary to pass on the model \n",
    "    messages_dictionary.append({\n",
    "        \"role\": \"user\",\n",
    "        \"content\": user_input\n",
    "    })\n",
    "    \n",
    "    # Response from the model to user input \n",
    "    response = oai_client.chat.completions.create(\n",
    "        model='gpt-4o',\n",
    "        messages=sales_agent_prompt + messages_dictionary, \n",
    "        tools=TOOLS\n",
    "    )\n",
    "    \n",
    "    tool_calls = response.choices[0].message.tool_calls\n",
    "    \n",
    "    # Check if model wants to call a tool  \n",
    "    if tool_calls: \n",
    "        tool_function_name = tool_calls[0].function.name\n",
    "        if tool_function_name == \"get_order_details\":\n",
    "            # The pricing agent generates a detailed cart in JSON format, including item quantities and total prices, ensuring the user receives an accurate summary of their order.\n",
    "            # Let the user know bot is calculating the price \n",
    "            speak(finalize_order)\n",
    "            \n",
    "            response = oai_client.chat.completions.create(\n",
    "                model='gpt-4o',\n",
    "                messages=pricing_agent_prompt + messages_dictionary, \n",
    "                response_format={\"type\": \"json_object\"}\n",
    "            )\n",
    "            # Get the cart \n",
    "            # At this point the cart can be sent to the Point-of-sale system \n",
    "            cart = json.loads(response.choices[0].message.content)\n",
    "    \n",
    "            # Extracting the total price of the entire order\n",
    "            total_price = cart[\"total-price\"]\n",
    "            final_message = f\".. your total is {convert_to_words(total_price)}\"\n",
    "            \n",
    "            speak(final_message)\n",
    "            messages_dictionary.append({\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": finalize_order + \" \" + final_message\n",
    "                })\n",
    "            break;\n",
    "        elif tool_function_name == \"get_human_help\":\n",
    "            #  get_human_help function allows the assistant to gracefully transfer the conversation to a human agent if the user requests assistance or deviates from the order process.\n",
    "            speak(human_help_message)\n",
    "            messages_dictionary.append({\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": human_help_message\n",
    "                })\n",
    "            break;\n",
    "        else: \n",
    "            print(f\"Tool does not exist: {response.choices[0].message.tool_calls}\")\n",
    "    \n",
    "    # Get message content \n",
    "    response_message = response.choices[0].message.content\n",
    "    \n",
    "    # Append the message to messages dictionary \n",
    "    messages_dictionary.append({\n",
    "    \"role\": \"assistant\",\n",
    "    \"content\": response_message\n",
    "    })\n",
    "    speak(response_message)\n",
    "    \n",
    "    \n",
    "# Print the conversation\n",
    "print (\"*\" * 10 + \" Conversation log: \" + \"*\" * 10)\n",
    "print(json.dumps(messages_dictionary, indent=4))\n",
    "\n",
    "# Print the cart \n",
    "print(\"*\" * 10 + \" Cart: \" + \"*\" * 10)\n",
    "print(json.dumps(cart, indent=4))"
   ],
   "id": "8ea4a922b0f1e8ae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent speaking ... (pre-recorded audio)\n",
      "Agent listening ...\n",
      "* done listening\n",
      "Agent speaking ...(new audio file generated)\n",
      "Agent listening ...\n",
      "* done listening\n",
      "Agent speaking ... (pre-recorded audio)\n",
      "Agent speaking ...(new audio file generated)\n",
      "********** Conversation log: **********\n",
      "[\n",
      "    {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"What would you like to order?\"\n",
      "    },\n",
      "    {\n",
      "        \"role\": \"user\",\n",
      "        \"content\": \"Hi, can I get four pencils and printing paper?\"\n",
      "    },\n",
      "    {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"Order: 4 pencils, and printing paper. ANYTHING ELSE?\"\n",
      "    },\n",
      "    {\n",
      "        \"role\": \"user\",\n",
      "        \"content\": \"That will be all. Thank you.\"\n",
      "    },\n",
      "    {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"Thank you for your order, let me calculate the total price. Your total is 7 dollars and 0 cents\"\n",
      "    }\n",
      "]\n",
      "********** Cart: **********\n",
      "{\n",
      "    \"cart\": [\n",
      "        {\n",
      "            \"item-id\": \"0001\",\n",
      "            \"item-name\": \"pencil\",\n",
      "            \"quantity\": 4,\n",
      "            \"item-price\": \"$0.50\",\n",
      "            \"total-item-price\": \"$2.00\"\n",
      "        },\n",
      "        {\n",
      "            \"item-id\": \"0005\",\n",
      "            \"item-name\": \"printing paper\",\n",
      "            \"quantity\": 1,\n",
      "            \"item-price\": \"$5.00\",\n",
      "            \"total-item-price\": \"$5.00\"\n",
      "        }\n",
      "    ],\n",
      "    \"total-price\": \"$7.00\"\n",
      "}\n"
     ]
    }
   ],
   "execution_count": 78
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Conclusion\n",
    "\n",
    "In this notebook, we developed an interactive and efficient voice chatbot capable of handling sales orders for office stationery. The conversation loop effectively manages user interactions, leveraging the GPT model for intelligent responses and ensuring the user's needs are met—whether by completing an order or escalating to a human agent. We pre-recorded common phrases to improve the latency, and provided visual cues to the user when the model is speaking and listening for coordinated conversation. This setup provides a solid foundation for building advanced voice-based chatbots with order management capabilities.\n",
    "\n",
    "### Tips and Tricks to Improve User Experience for STT/TTS Voice Bot Solutions\n",
    "\n",
    "Due to the inherent lag introduced by speech-to-text (STT) and text-to-speech (TTS) conversions, optimizing the user experience is crucial. Here are some strategies to enhance the responsiveness and fluidity of the conversation:\n",
    "\n",
    "- **Provide Visual Cues**: Implement visual indicators, when possible, to show when the model is speaking or listening, keeping users informed about the bot's status.  \n",
    "- **Chunk Incoming Audio**: Segment incoming audio at silence intervals before processing with Whisper or any ASR solution to reduce latency.  \n",
    "- **Pre-Record Common Phrases**: Use pre-recorded audio for frequently used phrases like welcome messages or notifications about escalating to a human agent, which can save processing time.  \n",
    "- **Keep Responses Concise**: Encourage the model to generate shorter text outputs and abbreviate common responses to speed up TTS processing.  \n",
    "- **Stream Output Audio**: Stream the audio output as it is generated, rather than waiting for the entire audio file to be ready, to provide a more seamless conversational experience.  \n"
   ],
   "id": "8ffaf64b5c8b9b54"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
