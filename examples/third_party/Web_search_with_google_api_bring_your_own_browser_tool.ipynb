{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Building a Bring Your Own Browser (BYOB) Tool for Web Browsing and Summarization\n",
    "\n",
    "**Disclaimer: This cookbook is for educational purposes only. Ensure that you comply with all applicable laws and service terms when using web search and scraping technologies. This cookbook will restrict the search to openai.com domain to retrieve the public information to illustrate the concepts.**\n",
    "\n",
    "Large Language Models (LLMs) like GPT-4 have a knowledge cutoff date, which means they lack information about events that occurred after that point. In scenarios where the most recent data is essential, it's necessary to provide LLMs with access to current web information to ensure accurate and relevant responses.\n",
    "\n",
    "In this guide, we will build a Bring Your Own Browser (BYOB) tool using Python to overcome this limitation. Our goal is to create a system that helps us compile a list of the most recent product launches by OpenAI. By integrating web search capabilities with an LLM, we'll enable the model to generate responses based on the latest information available online.\n",
    "\n",
    "While you can use any publicly available search APIs, we'll utilize Google's Custom Search API to perform web searches. The retrieved information from the search results will be processed and passed to the LLM to generate the final response through Retrieval-Augmented Generation (RAG).\n",
    "\n",
    "**Bring Your Own Browser (BYOB)** tools allow users to perform web browsing tasks programmatically. In this notebook, we'll create a BYOB tool that:\n",
    "\n",
    "**#1 Set Up a Search Engine:** Use a public search API, like Google's Custom Search API, to perform web searches and obtain a list of relevant search results.  \n",
    "\n",
    "**#2 Build a Search Dictionary:** Collect the title, URL, and a summary of each web page from the search results to create a structured dictionary of information.  \n",
    "\n",
    "**#3. Generate a RAG Response:** Implement Retrieval-Augmented Generation (RAG) by passing the gathered information to the LLM, which then generates a final response to the user's query.\n",
    "\n"
   ],
   "id": "7f59879cabc55a5e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Setting up a BYOB tool\n",
    "Before we begin, ensure you have the following: **Python 3.12 or later** installed on your machine. You will also need a Google Custom Search API key and Custom Search Engine ID (CSE ID). Necessary Python packages installed: `requests`, `beautifulsoup4`, `openai`. And ensure the OPENAI_API_KEY is set up as an environment variable.\n",
    "\n",
    "#### Step 1: Set Up a Search Engine to Provide Web Search Results\n",
    "You can use any publicly available web search APIs to perform this task. We will configure a custom search engine using Google's Custom Search API. This engine will fetch a list of relevant web pages based on the user's query, focusing on obtaining the most recent and pertinent results.  \n",
    "\n",
    "**a. Obtain API Credentials:** Acquire a Google API key and a Custom Search Engine ID (CSE ID) from the Google Developers Console. You can navigate to this [Programmable Search Engine Link](https://developers.google.com/custom-search/v1/overview) to set up an API key as well as Search Engine ID. \n",
    "\n",
    "**b. Configure Search Function:** The `search` function below sets up the search based on search term, the API and CSE ID keys, as well as number of search results to return. We'll introduce a parameter `site_filter` to restrict the output to only `openai.com`\n",
    "  "
   ],
   "id": "1a766088c001c30b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T22:39:14.226669Z",
     "start_time": "2024-09-09T22:39:14.220749Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def search(search_item, api_key, cse_id, search_depth=10, site_filter=None):\n",
    "    service_url = 'https://www.googleapis.com/customsearch/v1'\n",
    "\n",
    "    params = {\n",
    "        'q': search_item,\n",
    "        'key': api_key,\n",
    "        'cx': cse_id,\n",
    "        'num': search_depth\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(service_url, params=params)\n",
    "        response.raise_for_status()\n",
    "        results = response.json()\n",
    "\n",
    "        # Check if 'items' exists in the results\n",
    "        if 'items' in results:\n",
    "            if site_filter is not None:\n",
    "                \n",
    "                # Filter results to include only those with site_filter in the link\n",
    "                filtered_results = [result for result in results['items'] if site_filter in result['link']]\n",
    "\n",
    "                if filtered_results:\n",
    "                    return filtered_results\n",
    "                else:\n",
    "                    print(f\"No results with {site_filter} found.\")\n",
    "                    return []\n",
    "            else:\n",
    "                if 'items' in results:\n",
    "                    return results['items']\n",
    "                else:\n",
    "                    print(\"No search results found.\")\n",
    "                    return []\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"An error occurred during the search: {e}\")\n",
    "        return []\n"
   ],
   "id": "7df836efe1589633",
   "outputs": [],
   "execution_count": 124
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**c. Identify the search terms for search engine:** Typically the natural language prompt does not produce the desired results on the search engine. An effective approach is to use LLM to produce the right search term before invoking the search function.   \n",
    "\n",
    "In this example, we have the `search_query` as the user's desire to list OpenAI product launches in the reverse chronological order. In order to retrieve meaningful results, we first invoke the search engine to produce relevant search terms. "
   ],
   "id": "dcee6754a2e6cd24"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T22:39:17.687041Z",
     "start_time": "2024-09-09T22:39:16.201904Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "search_query = \"List the latest OpenAI product launches in chronological order from latest to oldest in the past 2 years\"\n",
    "\n",
    "search_term = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Provide a google search term based on search query provided below in 3-4 words\"},\n",
    "        {\"role\": \"user\", \"content\": search_query}]\n",
    ").choices[0].message.content\n",
    "\n",
    "print(search_term)"
   ],
   "id": "3752702114df8160",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI recent product launches\n"
     ]
    }
   ],
   "execution_count": 125
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**d. Invoke the search function:** Given the search result, we will invoke the search function to retrieve the results. The results only have the link of the web page and a snippet at this point. ",
   "id": "62b7194aedbc3a21"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T22:39:21.242133Z",
     "start_time": "2024-09-09T22:39:20.562921Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv('.env')\n",
    "\n",
    "api_key = os.getenv('API_KEY')\n",
    "cse_id = os.getenv('CSE_ID')\n",
    "\n",
    "search_items = search(search_item=search_term, api_key=api_key, cse_id=cse_id, search_depth=10, site_filter=\"https://openai.com\")\n"
   ],
   "id": "891e924b15957206",
   "outputs": [],
   "execution_count": 126
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T22:39:21.999890Z",
     "start_time": "2024-09-09T22:39:21.996702Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for item in search_items:\n",
    "    print(f\"Link: {item['link']}\")\n",
    "    print(f\"Snippet: {item['snippet']}\\n\")"
   ],
   "id": "ceedee1eb3ffec85",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Link: https://openai.com/index/new-models-and-developer-products-announced-at-devday/\n",
      "Snippet: Nov 6, 2023 ... GPT-4 Turbo with 128K context · We released the first version of GPT-4 in March and made GPT-4 generally available to all developers in July.\n",
      "\n",
      "Link: https://openai.com/news/\n",
      "Snippet: Product · Product. Jul 25, 2024. SearchGPT is a prototype of new AI search features. Home > News > Card ... (opens in a new window) (opens in a new window)\n",
      "\n"
     ]
    }
   ],
   "execution_count": 127
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Step 2: Build a Search Dictionary with Titles, URLs, and Summaries of Web Pages\n",
    "After obtaining the search results, we'll extract and organize the relevant information, so it can be passed to the LLM for final output. \n",
    "\n",
    "**a. Scrape Web Page Content:** For each URL in the search results, retrieve the web page to extract textual content while filtering out non-relevant data like scripts and advertisements as demonstrated in function `retrieve_content`. \n",
    "\n",
    "**b. Summarize Content:** Use an LLM to generate concise summaries of the scraped content, focusing on information pertinent to the user's query. Model can be provided the original search text, so it can focus on summarizing the content for the search intent as outlined in function `summarize_content`. \n",
    "  \n",
    "**c. Create a Structured Dictionary:** Organize the data into a dictionary or a DataFrame containing the title, link, and summary for each web page. This structure can be passed on to the LLM to generate the summary with the appropriate citations.    \n"
   ],
   "id": "c2f754f92866307e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T22:39:35.435363Z",
     "start_time": "2024-09-09T22:39:35.429106Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "TRUNCATE_SCRAPED_TEXT = 50000  # Adjust based on your model's context window\n",
    "SEARCH_DEPTH = 5\n",
    "\n",
    "def retrieve_content(url, max_tokens=TRUNCATE_SCRAPED_TEXT):\n",
    "        try:\n",
    "            headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "            response = requests.get(url, headers=headers, timeout=10)\n",
    "            response.raise_for_status()\n",
    "\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            for script_or_style in soup(['script', 'style']):\n",
    "                script_or_style.decompose()\n",
    "\n",
    "            text = soup.get_text(separator=' ', strip=True)\n",
    "            characters = max_tokens * 4  # Approximate conversion\n",
    "            text = text[:characters]\n",
    "            return text\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Failed to retrieve {url}: {e}\")\n",
    "            return None\n",
    "        \n",
    "def summarize_content(content, search_term, character_limit=500):\n",
    "        prompt = (\n",
    "            f\"You are an AI assistant tasked with summarizing content relevant to '{search_term}'. \"\n",
    "            f\"Please provide a concise summary in {character_limit} characters or less.\"\n",
    "        )\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": prompt},\n",
    "                    {\"role\": \"user\", \"content\": content}]\n",
    "            )\n",
    "            summary = response.choices[0].message.content\n",
    "            return summary\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred during summarization: {e}\")\n",
    "            return None\n",
    "\n",
    "def get_search_results(search_items, character_limit=500):\n",
    "    # Generate a summary of search results for the given search term\n",
    "    results_list = []\n",
    "    for idx, item in enumerate(search_items, start=1):\n",
    "        url = item.get('link')\n",
    "        \n",
    "        snippet = item.get('snippet', '')\n",
    "        web_content = retrieve_content(url, TRUNCATE_SCRAPED_TEXT)\n",
    "        \n",
    "        if web_content is None:\n",
    "            print(f\"Error: skipped URL: {url}\")\n",
    "        else:\n",
    "            summary = summarize_content(web_content, search_term, character_limit)\n",
    "            result_dict = {\n",
    "                'order': idx,\n",
    "                'link': url,\n",
    "                'title': snippet,\n",
    "                'Summary': summary\n",
    "            }\n",
    "            results_list.append(result_dict)\n",
    "    return results_list"
   ],
   "id": "f4981ca230333116",
   "outputs": [],
   "execution_count": 128
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T22:39:41.263863Z",
     "start_time": "2024-09-09T22:39:36.880784Z"
    }
   },
   "cell_type": "code",
   "source": [
    "results = get_search_results(search_items)\n",
    "\n",
    "for result in results:\n",
    "    print(f\"Search order: {result['order']}\")\n",
    "    print(f\"Link: {result['link']}\")\n",
    "    print(f\"Snippet: {result['title']}\")\n",
    "    print(f\"Summary: {result['Summary']}\")\n",
    "    print('-' * 80)"
   ],
   "id": "6b9afc6c933a6a67",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search order: 1\n",
      "Link: https://openai.com/index/new-models-and-developer-products-announced-at-devday/\n",
      "Snippet: Nov 6, 2023 ... GPT-4 Turbo with 128K context · We released the first version of GPT-4 in March and made GPT-4 generally available to all developers in July.\n",
      "Summary: At OpenAI's recent DevDay, several new products and updates were announced, including the launch of GPT-4 Turbo with a 128K context window, a new Assistants API, and enhanced multimodal capabilities. Key features include lower prices for models and expanded API functionalities such as code interpretation and real-time image processing. DALL·E 3 integration and a new text-to-speech model were also introduced. Additionally, OpenAI is implementing a Copyright Shield to protect customers from legal claims related to copyright infringement.\n",
      "--------------------------------------------------------------------------------\n",
      "Search order: 2\n",
      "Link: https://openai.com/news/\n",
      "Snippet: Product · Product. Jul 25, 2024. SearchGPT is a prototype of new AI search features. Home > News > Card ... (opens in a new window) (opens in a new window)\n",
      "Summary: OpenAI has launched several significant products in 2024, including the prototype SearchGPT and GPT-4o mini aimed at cost-efficient intelligence. The organization introduced ChatGPT Edu tailored for educational needs and improved data analysis capabilities in ChatGPT. OpenAI for Nonprofits was also unveiled, emphasizing support for non-profit organizations. Additionally, enhancements to the fine-tuning API and custom models program were made. These updates reflect OpenAI’s commitment to advancing AI technology while ensuring accessibility and safety in various sectors.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 129
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Step 3: Generate a RAG Response to the User Query\n",
    "With the search data organized in a JSON data structure, we will pass this information to the LLM with the original user query to generate the final response. Now LLM response includes information beyond its original knowledge cutoff, providing current insights."
   ],
   "id": "3f81cf3fd1a942c3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T22:39:55.574414Z",
     "start_time": "2024-09-09T22:39:51.014993Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json \n",
    "\n",
    "final_prompt = (\n",
    "    f\"The user will provide a dictionary of search results in JSON format for search query {search_term} Based on on the search results provided by the user, provide a detailed response to this query: **'{search_query}'**. Make sure to cite all the sources at the end of your answer.\"\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": final_prompt},\n",
    "        {\"role\": \"user\", \"content\": json.dumps(results)}],\n",
    "    temperature=0\n",
    "\n",
    ")\n",
    "summary = response.choices[0].message.content\n",
    "\n",
    "print(summary)"
   ],
   "id": "2894a01ce6c44d36",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided search results, here is a chronological list of the latest OpenAI product launches in the past two years, from the most recent to the oldest:\n",
      "\n",
      "1. **November 6, 2023**:\n",
      "   - **GPT-4 Turbo with 128K context**: An enhanced version of GPT-4 with a larger context window.\n",
      "   - **Assistants API**: A new API for creating custom AI assistants.\n",
      "   - **Enhanced Multimodal Capabilities**: Improvements in handling multiple types of data inputs.\n",
      "   - **DALL·E 3 Integration**: Integration of the latest version of the DALL·E image generation model.\n",
      "   - **Text-to-Speech Model**: Introduction of a new model for converting text to speech.\n",
      "   - **Copyright Shield**: A new feature to protect customers from legal claims related to copyright infringement.\n",
      "\n",
      "2. **July 25, 2024**:\n",
      "   - **SearchGPT**: A prototype for new AI search features.\n",
      "   - **GPT-4o Mini**: A cost-efficient version of GPT-4.\n",
      "   - **ChatGPT Edu**: A version of ChatGPT tailored for educational purposes.\n",
      "   - **OpenAI for Nonprofits**: A program to support non-profit organizations.\n",
      "   - **Enhanced Data Analysis in ChatGPT**: Improvements in data analysis capabilities.\n",
      "   - **Fine-Tuning API and Custom Models Program**: Enhancements to the API for fine-tuning and creating custom models.\n",
      "\n",
      "### Sources:\n",
      "1. [OpenAI DevDay Announcements](https://openai.com/index/new-models-and-developer-products-announced-at-devday/)\n",
      "2. [OpenAI News](https://openai.com/news/)\n"
     ]
    }
   ],
   "execution_count": 130
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Conclusion\n",
    " \n",
    "Large Language Models (LLMs) have a knowledge cutoff and may not be aware of recent events. To provide them with the latest information, you can build a Bring Your Own Browser (BYOB) tool using Python. This tool retrieves current web data and feeds it to the LLM, enabling up-to-date responses.\n",
    "\n",
    "The process involves three main steps:\n",
    "\n",
    "**#1 Set Up a Search Engine:** Use a public search API, like Google's Custom Search API, to perform web searches and obtain a list of relevant search results.  \n",
    "\n",
    "**#2 Build a Search Dictionary:** Collect the title, URL, and a summary of each web page from the search results to create a structured dictionary of information.  \n",
    "\n",
    "**#3. Generate a RAG Response:** Implement Retrieval-Augmented Generation (RAG) by passing the gathered information to the LLM, which then generates a final response to the user's query.\n",
    "\n",
    "By following these steps, you enhance the LLMs ability to provide up-to-date answers in your application that include the most recent developments, such as the latest product launches by OpenAI."
   ],
   "id": "8b6beba8859f1bc7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
