{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assistants API Overview with Streaming (Python SDK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new [Assistants API](https://platform.openai.com/docs/assistants/overview) is a stateful evolution of our [Chat Completions API](https://platform.openai.com/docs/guides/text-generation/chat-completions-api) meant to simplify the creation of assistant-like experiences, and enable developer access to powerful tools like Code Interpreter, Retrieval and Function Calling. The API now also supports streaming, which means you can build real-time experiences for your UI.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Assistants API Diagram](../images/assistants_overview_diagram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat Completions API vs Assistants API\n",
    "\n",
    "The primitives of the **Chat Completions API** are `Messages`, on which you perform a `Completion` with a `Model` (`gpt-3.5-turbo`, `gpt-4`, etc). It is lightweight and powerful, but inherently stateless, which means you have to manage conversation state, tool definitions, retrieval documents, and code execution manually.\n",
    "\n",
    "In contrast, the primitives of the **Assistants API** are\n",
    "\n",
    "- `Assistants`, which encapsulate a base model, instructions, tools, and (context) documents,\n",
    "- `Threads`, which represent the state of a conversation, and\n",
    "- `Runs`, which power the execution of an `Assistant` on a `Thread`, including textual responses and multi-step tool use.\n",
    "\n",
    "We'll take a look at how these can be used to create powerful, stateful experiences.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "### Python SDK\n",
    "\n",
    "> **Note**\n",
    "> We've updated our [Python SDK](https://github.com/openai/openai-python) to add support for the Assistants API, so you'll need to update it to the latest version (`1.2.3` at time of writing).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And make sure it's up to date by running:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version: 1.2.3\n"
     ]
    }
   ],
   "source": [
    "!pip show openai | grep Version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretty Printing Helper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def show_json(obj):\n",
    "    display(json.loads(obj.model_dump_json()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Example with Assistants API\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assistants\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The easiest way to get started with the Assistants API is through the [Assistants Playground](https://platform.openai.com/playground).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Assistants Playground](../images/assistants_overview_assistants_playground.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by creating an assistant! We'll create a Math Tutor just like in our [docs](https://platform.openai.com/docs/assistants/overview).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Creating New Assistant](../images/assistants_overview_new_assistant.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can view Assistants you've created in the [Assistants Dashboard](https://platform.openai.com/assistants).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Assistants Dashboard](../images/assistants_overview_assistants_dashboard.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also create Assistants directly through the Assistants API, like so:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'asst_2Hfaqc71l3fu7pvbd1PkPrpf',\n",
       " 'created_at': 1711920054,\n",
       " 'description': None,\n",
       " 'file_ids': [],\n",
       " 'instructions': 'You are a personal math tutor. Answer questions briefly, in a sentence or less.',\n",
       " 'metadata': {},\n",
       " 'model': 'gpt-4-1106-preview',\n",
       " 'name': 'Math Tutor',\n",
       " 'object': 'assistant',\n",
       " 'tools': []}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\", \"<your OpenAI API key if not set as env var>\"))\n",
    "\n",
    "\n",
    "assistant = client.beta.assistants.create(\n",
    "    name=\"Math Tutor\",\n",
    "    instructions=\"You are a personal math tutor. Answer questions briefly, in a sentence or less.\",\n",
    "    model=\"gpt-4-1106-preview\",\n",
    ")\n",
    "show_json(assistant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regardless of whether you create your Assistant through the Dashboard or with the API, you'll want to keep track of the Assistant ID. This is how you'll refer to your Assistant throughout Threads and Runs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll create a new Thread and add a Message to it. This will hold the state of our conversation, so we don't have re-send the entire message history each time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threads\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new thread:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'thread_LFIvmULMH7dUmorXIIcCmNEb',\n",
       " 'created_at': 1711920081,\n",
       " 'metadata': {},\n",
       " 'object': 'thread'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "thread = client.beta.threads.create()\n",
    "show_json(thread)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then add the Message to the thread:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'msg_88FLsE82A89fyYRAYRuuuKWA',\n",
       " 'assistant_id': None,\n",
       " 'completed_at': None,\n",
       " 'content': [{'text': {'annotations': [],\n",
       "    'value': 'I need to solve the equation `3x + 11 = 14`. Can you help me?'},\n",
       "   'type': 'text'}],\n",
       " 'created_at': 1711920085,\n",
       " 'file_ids': [],\n",
       " 'incomplete_at': None,\n",
       " 'incomplete_details': None,\n",
       " 'metadata': {},\n",
       " 'object': 'thread.message',\n",
       " 'role': 'user',\n",
       " 'run_id': None,\n",
       " 'status': None,\n",
       " 'thread_id': 'thread_LFIvmULMH7dUmorXIIcCmNEb'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"I need to solve the equation `3x + 11 = 14`. Can you help me?\",\n",
    ")\n",
    "show_json(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note**\n",
    "> Even though you're no longer sending the entire history each time, you will still be charged for the tokens of the entire conversation history with each Run.\n",
    "\n",
    "Notice how the Thread we created is **not** associated with the Assistant we created earlier! Threads exist independently from Assistants, which may be different from what you'd expect if you've used ChatGPT (where a thread is tied to a model/GPT)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming Runs\n",
    "\n",
    "To get a completion from an Assistant for a given Thread, we must create a Run. Creating a Run will indicate to an Assistant that it should look at the messages in the Thread and take action: either by adding a single response, or using tools.\n",
    "\n",
    "> **Note**\n",
    "> Runs are a key difference between the Assistants API and Chat Completions API. While in Chat Completions the model will only ever respond with a single message, in the Assistants API a Run may result in an Assistant using one or multiple tools, and potentially adding multiple messages to the Thread.\n",
    "\n",
    "In order to get the Assistant's response as a stream, we have to do a couple of things when setting up the run. First, we define an EventHandler class that specifies how we want to handle events in the response stream. Second, we use the 'create and stream' helper in the Python SDK to actually create the Run and stream the response. You only need to define EventHandler once, but every time you add a message to a thread and want to run it, you'd use the create_and_stream helper function again. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "assistant > Absolutely, I'd be happy to help you solve the equation `3x + 11 = 14`. The goal here is to isolate x (get x by itself on one side of the equation). Here are the steps to do that:\n",
      "\n",
      "1. **Subtract 11 from both sides**: You want to move the constant term (11) from the left side to the right side to isolate the variable term (3x). To maintain the equality, whatever you do to one side, you must do to the other.\n",
      "\n",
      "    3x + 11 - 11 = 14 - 11\n",
      "\n",
      "    This simplifies to:\n",
      "\n",
      "    3x = 3\n",
      "\n",
      "2. **Divide both sides by 3**: Now that we have 3x on one side, we need to get x alone. Since x is being multiplied by 3, we can do the opposite operation, which is division by 3, to both sides of the equation.\n",
      "\n",
      "    3x / 3 = 3 / 3\n",
      "\n",
      "    This simplifies to:\n",
      "\n",
      "    x = 1\n",
      "\n",
      "You now have the solution to the equation, which is x = 1."
     ]
    }
   ],
   "source": [
    "from typing_extensions import override\n",
    "from openai import AssistantEventHandler\n",
    "\n",
    "\n",
    "class EventHandler(AssistantEventHandler):    \n",
    "  @override\n",
    "  def on_text_created(self, text) -> None:\n",
    "    print(f\"\\nassistant > \", end=\"\", flush=True)\n",
    "      \n",
    "  @override\n",
    "  def on_text_delta(self, delta, snapshot):\n",
    "    print(delta.value, end=\"\", flush=True)\n",
    "      \n",
    "  def on_tool_call_created(self, tool_call):\n",
    "    print(f\"\\nassistant > {tool_call.type}\\n\", flush=True)\n",
    "  \n",
    "  def on_tool_call_delta(self, delta, snapshot):\n",
    "    if delta.type == 'code_interpreter':\n",
    "      if delta.code_interpreter.input:\n",
    "        print(delta.code_interpreter.input, end=\"\", flush=True)\n",
    "      if delta.code_interpreter.outputs:\n",
    "        print(f\"\\n\\noutput >\", flush=True)\n",
    "        for output in delta.code_interpreter.outputs:\n",
    "          if output.type == \"logs\":\n",
    "            print(f\"\\n{output.logs}\", flush=True)\n",
    "\n",
    "\n",
    "\n",
    "with client.beta.threads.runs.create_and_stream(\n",
    "  thread_id=thread.id,\n",
    "  assistant_id=assistant.id,\n",
    "  instructions=\"Please be a friendly math tutor and explain all of your steps for solving a question.\",\n",
    "  event_handler=EventHandler(),\n",
    ") as stream:\n",
    "  stream.until_done()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Messages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the Run has completed, we can list the Messages in the Thread to see what got added by the Assistant.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': [{'id': 'msg_43Iu2C9eofqEesCULzGwjEyR',\n",
       "   'assistant_id': 'asst_2Hfaqc71l3fu7pvbd1PkPrpf',\n",
       "   'completed_at': None,\n",
       "   'content': [{'text': {'annotations': [],\n",
       "      'value': \"Absolutely, I'd be happy to help you solve the equation `3x + 11 = 14`. The goal here is to isolate x (get x by itself on one side of the equation). Here are the steps to do that:\\n\\n1. **Subtract 11 from both sides**: You want to move the constant term (11) from the left side to the right side to isolate the variable term (3x). To maintain the equality, whatever you do to one side, you must do to the other.\\n\\n    3x + 11 - 11 = 14 - 11\\n\\n    This simplifies to:\\n\\n    3x = 3\\n\\n2. **Divide both sides by 3**: Now that we have 3x on one side, we need to get x alone. Since x is being multiplied by 3, we can do the opposite operation, which is division by 3, to both sides of the equation.\\n\\n    3x / 3 = 3 / 3\\n\\n    This simplifies to:\\n\\n    x = 1\\n\\nYou now have the solution to the equation, which is x = 1.\"},\n",
       "     'type': 'text'}],\n",
       "   'created_at': 1711921887,\n",
       "   'file_ids': [],\n",
       "   'incomplete_at': None,\n",
       "   'incomplete_details': None,\n",
       "   'metadata': {},\n",
       "   'object': 'thread.message',\n",
       "   'role': 'assistant',\n",
       "   'run_id': 'run_bEB2mvszofeXTZPJqqAFVLrr',\n",
       "   'status': None,\n",
       "   'thread_id': 'thread_LFIvmULMH7dUmorXIIcCmNEb'},\n",
       "  {'id': 'msg_88FLsE82A89fyYRAYRuuuKWA',\n",
       "   'assistant_id': None,\n",
       "   'completed_at': None,\n",
       "   'content': [{'text': {'annotations': [],\n",
       "      'value': 'I need to solve the equation `3x + 11 = 14`. Can you help me?'},\n",
       "     'type': 'text'}],\n",
       "   'created_at': 1711920085,\n",
       "   'file_ids': [],\n",
       "   'incomplete_at': None,\n",
       "   'incomplete_details': None,\n",
       "   'metadata': {},\n",
       "   'object': 'thread.message',\n",
       "   'role': 'user',\n",
       "   'run_id': None,\n",
       "   'status': None,\n",
       "   'thread_id': 'thread_LFIvmULMH7dUmorXIIcCmNEb'}],\n",
       " 'object': 'list',\n",
       " 'first_id': 'msg_43Iu2C9eofqEesCULzGwjEyR',\n",
       " 'last_id': 'msg_88FLsE82A89fyYRAYRuuuKWA',\n",
       " 'has_more': False}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "show_json(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, Messages are ordered in reverse-chronological order – this was done so the most recent results are always on the first `page` (since results can be paginated). Do keep a look out for this, since this is the opposite order to messages in the Chat Completions API.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's ask our Assistant to explain the result a bit further!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "assistant > Of course, I'll explain each step in more detail.\n",
      "\n",
      "You're given the equation:\n",
      "\n",
      "`3x + 11 = 14`\n",
      "\n",
      "The goal is to solve for x, which means we want to find the value of x that makes this statement true. We need to isolate x on one side of the equation, which means we want to end up with an equation that looks like `x = ` some number.\n",
      "\n",
      "Here's how we do it, step by step:\n",
      "\n",
      "### Step 1: Subtract 11 from both sides.\n",
      "We start by looking at the `+11` on the left side of the equation. We want to get rid of it so that we only have the term with x (the 3x) on that side. To do this, we do the opposite operation, which is subtraction. We subtract 11 from both sides of the equation:\n",
      "\n",
      "`3x + 11 - 11 = 14 - 11`\n",
      "\n",
      "On the left side, by subtracting 11 from 11, we get 0, so they cancel each other out. This leaves us with just `3x` on the left side.\n",
      "\n",
      "On the right side, subtracting 11 from 14 gives us 3.\n",
      "\n",
      "After performing the subtraction, the equation looks like this:\n",
      "\n",
      "`3x = 3`\n",
      "\n",
      "### Step 2: Divide both sides by 3.\n",
      "The next step is to isolate x completely. Right now, x is being multiplied by 3. To undo this multiplication, we divide both sides of the equation by 3, the number that's multiplying x.\n",
      "\n",
      "`3x / 3 = 3 / 3`\n",
      "\n",
      "Doing this on the left side, the 3s cancel out because any number divided by itself is 1. What we have left is 1x, which is the same as just x.\n",
      "\n",
      "`x = 1`\n",
      "\n",
      "On the right side, 3 divided by 3 also equals 1.\n",
      "\n",
      "So, the simplification of the division step gives us the final answer:\n",
      "\n",
      "`x = 1`\n",
      "\n",
      "### Conclusion\n",
      "We've now solved for x by performing two operations: subtracting 11 from both sides to get rid of the constant term and then dividing both sides by 3 to get rid of the coefficient of x. This gives us the solution for the equation, which is `x = 1`."
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data': [{'id': 'msg_gFvDVfgTgGvQeGcipEGr4AkE',\n",
       "   'assistant_id': 'asst_2Hfaqc71l3fu7pvbd1PkPrpf',\n",
       "   'completed_at': None,\n",
       "   'content': [{'text': {'annotations': [],\n",
       "      'value': \"Of course, I'll explain each step in more detail.\\n\\nYou're given the equation:\\n\\n`3x + 11 = 14`\\n\\nThe goal is to solve for x, which means we want to find the value of x that makes this statement true. We need to isolate x on one side of the equation, which means we want to end up with an equation that looks like `x = ` some number.\\n\\nHere's how we do it, step by step:\\n\\n### Step 1: Subtract 11 from both sides.\\nWe start by looking at the `+11` on the left side of the equation. We want to get rid of it so that we only have the term with x (the 3x) on that side. To do this, we do the opposite operation, which is subtraction. We subtract 11 from both sides of the equation:\\n\\n`3x + 11 - 11 = 14 - 11`\\n\\nOn the left side, by subtracting 11 from 11, we get 0, so they cancel each other out. This leaves us with just `3x` on the left side.\\n\\nOn the right side, subtracting 11 from 14 gives us 3.\\n\\nAfter performing the subtraction, the equation looks like this:\\n\\n`3x = 3`\\n\\n### Step 2: Divide both sides by 3.\\nThe next step is to isolate x completely. Right now, x is being multiplied by 3. To undo this multiplication, we divide both sides of the equation by 3, the number that's multiplying x.\\n\\n`3x / 3 = 3 / 3`\\n\\nDoing this on the left side, the 3s cancel out because any number divided by itself is 1. What we have left is 1x, which is the same as just x.\\n\\n`x = 1`\\n\\nOn the right side, 3 divided by 3 also equals 1.\\n\\nSo, the simplification of the division step gives us the final answer:\\n\\n`x = 1`\\n\\n### Conclusion\\nWe've now solved for x by performing two operations: subtracting 11 from both sides to get rid of the constant term and then dividing both sides by 3 to get rid of the coefficient of x. This gives us the solution for the equation, which is `x = 1`.\"},\n",
       "     'type': 'text'}],\n",
       "   'created_at': 1711922159,\n",
       "   'file_ids': [],\n",
       "   'incomplete_at': None,\n",
       "   'incomplete_details': None,\n",
       "   'metadata': {},\n",
       "   'object': 'thread.message',\n",
       "   'role': 'assistant',\n",
       "   'run_id': 'run_c6XJAi9f0so3Tz3eHFpZsAkV',\n",
       "   'status': None,\n",
       "   'thread_id': 'thread_LFIvmULMH7dUmorXIIcCmNEb'}],\n",
       " 'object': 'list',\n",
       " 'first_id': 'msg_gFvDVfgTgGvQeGcipEGr4AkE',\n",
       " 'last_id': 'msg_gFvDVfgTgGvQeGcipEGr4AkE',\n",
       " 'has_more': False}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a message to append to our thread\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id, role=\"user\", content=\"Could you explain this to me?\"\n",
    ")\n",
    "\n",
    "# Execute our run again to process the new message\n",
    "with client.beta.threads.runs.create_and_stream(\n",
    "  thread_id=thread.id,\n",
    "  assistant_id=assistant.id,\n",
    "  instructions=\"Please be a friendly math tutor and explain all of your steps for solving a question.\",\n",
    "  event_handler=EventHandler(),\n",
    ") as stream:\n",
    "  stream.until_done()\n",
    "\n",
    "\n",
    "# Retrieve all the messages added after our last user message\n",
    "messages = client.beta.threads.messages.list(\n",
    "    thread_id=thread.id, order=\"asc\", after=message.id\n",
    ")\n",
    "show_json(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This may feel like a lot of steps to get a response back, especially for this simple example. However, you'll soon see how we can add very powerful functionality to our Assistant without changing much code at all!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at how we could potentially put all of this together. Below is all the code you need to use an Assistant you've created.\n",
    "\n",
    "Since we've already created our Math Assistant, I've saved its ID in `MATH_ASSISTANT_ID`. I then defined two functions:\n",
    "\n",
    "- `submit_message`: create a Message on a Thread, then start and return a new Run\n",
    "- `get_response`: returns the list of Messages in a Thread\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from openai import AssistantEventHandler\n",
    "from typing_extensions import override\n",
    "import os \n",
    "\n",
    "MATH_ASSISTANT_ID = assistant.id  # or a hard-coded ID like \"asst-...\"\n",
    "\n",
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\", \"<your OpenAI API key if not set as env var>\"))\n",
    "\n",
    "class EventHandler(AssistantEventHandler):    \n",
    "  @override\n",
    "  def on_text_created(self, text) -> None:\n",
    "    print(f\"\\nassistant > \", end=\"\", flush=True)\n",
    "      \n",
    "  @override\n",
    "  def on_text_delta(self, delta, snapshot):\n",
    "    print(delta.value, end=\"\", flush=True)\n",
    "      \n",
    "  def on_tool_call_created(self, tool_call):\n",
    "    print(f\"\\nassistant > {tool_call.type}\\n\", flush=True)\n",
    "  \n",
    "  def on_tool_call_delta(self, delta, snapshot):\n",
    "    if delta.type == 'code_interpreter':\n",
    "      if delta.code_interpreter.input:\n",
    "        print(delta.code_interpreter.input, end=\"\", flush=True)\n",
    "      if delta.code_interpreter.outputs:\n",
    "        print(f\"\\n\\noutput >\", flush=True)\n",
    "        for output in delta.code_interpreter.outputs:\n",
    "          if output.type == \"logs\":\n",
    "            print(f\"\\n{output.logs}\", flush=True)\n",
    "\n",
    "def submit_message(assistant_id, thread, user_message):\n",
    "    # Submit the initial message to the thread\n",
    "    client.beta.threads.messages.create(\n",
    "        thread_id=thread.id, role=\"user\", content=user_message\n",
    "    )\n",
    "\n",
    "    # Create and stream the run with the given instructions\n",
    "    with client.beta.threads.runs.create_and_stream(\n",
    "        thread_id=thread.id,\n",
    "        assistant_id=assistant_id,\n",
    "        instructions=\"Please be a friendly math tutor.\",\n",
    "        event_handler=EventHandler(),\n",
    "    ) as stream:\n",
    "        stream.until_done()\n",
    "\n",
    "\n",
    "def get_response(thread):\n",
    "    return client.beta.threads.messages.list(thread_id=thread.id, order=\"asc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've also defined a `create_thread_and_run` function that I can re-use (which is actually almost identical to the [`client.beta.threads.create_and_run`](https://platform.openai.com/docs/api-reference/runs/createThreadAndRun) compound function in our API ;) ). Finally, we can submit our mock user requests each to a new Thread.\n",
    "\n",
    "Notice how all of these API calls are asynchronous operations; this means we actually get async behavior in our code without the use of async libraries! (e.g. `asyncio`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "assistant > code_interpreter\n",
      "\n",
      "from sympy import symbols, Eq, solve\n",
      "\n",
      "# Define the variable and equation\n",
      "x = symbols('x')\n",
      "equation = Eq(3*x + 11, 14)\n",
      "\n",
      "# Solving the equation\n",
      "solution = solve(equation, x)\n",
      "solution\n",
      "\n",
      "output >\n",
      "\n",
      "[1]\n",
      "\n",
      "assistant > Certainly! To solve the equation \\(3x + 11 = 14\\), you'll need to isolate the variable \\(x\\) on one side of the equation.\n",
      "\n",
      "Here's how we can do it step by step:\n",
      "1. Subtract 11 from both sides to start.\n",
      "\\[ 3x + 11 - 11 = 14 - 11 \\]\n",
      "\\[ 3x = 3 \\]\n",
      "\n",
      "2. Now, divide both sides by 3 to solve for \\(x\\).\n",
      "\\[ \\frac{3x}{3} = \\frac{3}{3} \\]\n",
      "\\[ x = 1 \\]\n",
      "\n",
      "So the solution to the equation is \\(x = 1\\).\n",
      "assistant > Sure, let's create a more challenging problem that involves multiple steps and possibly fractions or decimals. Here is an example:\n",
      "\n",
      "Solve for \\( x \\) in the equation:\n",
      "\n",
      "\\[ 4x - \\frac{5}{2} = \\frac{3x}{4} + 9.5 \\]\n",
      "\n",
      "This problem involves fractions and requires multiple steps to solve, including finding a common denominator and moving terms with \\( x \\) to one side of the equation. Would you like to try solving this problem, or do you need further assistance with it?"
     ]
    }
   ],
   "source": [
    "def create_thread_and_run(user_input):\n",
    "    thread = client.beta.threads.create()\n",
    "    run = submit_message(MATH_ASSISTANT_ID, thread, user_input)\n",
    "    return thread, run\n",
    "\n",
    "\n",
    "# Emulating concurrent user requests\n",
    "thread1, run1 = create_thread_and_run(\n",
    "    \"I need to solve the equation `3x + 11 = 14`. Can you help me?\"\n",
    ")\n",
    "thread2, run2 = create_thread_and_run(\"Can you generate another math problem like  `3x + 11 = 14` for me? Make it difficult.\")\n",
    "\n",
    "# Now all Runs are executing..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et voilà!\n",
    "\n",
    "You may have noticed that this code is not actually specific to our math Assistant at all... this code will work for any new Assistant you create simply by changing the Assistant ID! That is the power of the Assistants API.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools\n",
    "\n",
    "A key feature of the Assistants API is the ability to equip our Assistants with Tools, like Code Interpreter, Retrieval, and custom Functions. Let's take a look at each.\n",
    "\n",
    "### Code Interpreter\n",
    "\n",
    "Let's equip our Math Tutor with the [Code Interpreter](https://platform.openai.com/docs/assistants/tools/code-interpreter) tool, which we can do from the Dashboard...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Enabling code interpreter](../images/assistants_overview_enable_code_interpreter.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...or the API, using the Assistant ID.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'asst_2Hfaqc71l3fu7pvbd1PkPrpf',\n",
       " 'created_at': 1711920054,\n",
       " 'description': None,\n",
       " 'file_ids': [],\n",
       " 'instructions': 'You are a personal math tutor. Answer questions briefly, in a sentence or less.',\n",
       " 'metadata': {},\n",
       " 'model': 'gpt-4-1106-preview',\n",
       " 'name': 'Math Tutor',\n",
       " 'object': 'assistant',\n",
       " 'tools': [{'type': 'code_interpreter'}]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "assistant = client.beta.assistants.update(\n",
    "    MATH_ASSISTANT_ID,\n",
    "    tools=[{\"type\": \"code_interpreter\"}],\n",
    ")\n",
    "show_json(assistant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's ask the Assistant to use its new tool.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "assistant > code_interpreter\n",
      "\n",
      "# Function to generate the first n Fibonacci numbers\n",
      "def generate_fibonacci(n):\n",
      "    fib_sequence = [0, 1]\n",
      "    while len(fib_sequence) < n:\n",
      "        fib_sequence.append(fib_sequence[-1] + fib_sequence[-2])\n",
      "    return fib_sequence[:n]\n",
      "\n",
      "# Generate the first 20 Fibonacci numbers\n",
      "first_20_fib_numbers = generate_fibonacci(20)\n",
      "first_20_fib_numbers\n",
      "\n",
      "output >\n",
      "\n",
      "[0,\n",
      " 1,\n",
      " 1,\n",
      " 2,\n",
      " 3,\n",
      " 5,\n",
      " 8,\n",
      " 13,\n",
      " 21,\n",
      " 34,\n",
      " 55,\n",
      " 89,\n",
      " 144,\n",
      " 233,\n",
      " 377,\n",
      " 610,\n",
      " 987,\n",
      " 1597,\n",
      " 2584,\n",
      " 4181]\n",
      "\n",
      "assistant > The first 20 numbers in the Fibonacci sequence are:\n",
      "\n",
      "0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377, 610, 987, 1597, 2584, 4181."
     ]
    }
   ],
   "source": [
    "thread, run = create_thread_and_run(\n",
    "    \"Generate the first 20 fibbonaci numbers with code.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's it! The Assistant used Code Interpreter in the background, and gave us a final response.\n",
    "\n",
    "For some use cases this may be enough – however, if we want more details on what precisely an Assistant is doing we can take a look at a Run's Steps.\n",
    "\n",
    "### Steps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Run is composed of one or more Steps. Like a Run, each Step has a `status` that you can query. This is useful for surfacing the progress of a Step to a user (e.g. a spinner while the Assistant is writing code or performing retrieval).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m run_steps \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mbeta\u001b[38;5;241m.\u001b[39mthreads\u001b[38;5;241m.\u001b[39mruns\u001b[38;5;241m.\u001b[39msteps\u001b[38;5;241m.\u001b[39mlist(thread_id\u001b[38;5;241m=\u001b[39mthread\u001b[38;5;241m.\u001b[39mid, \n\u001b[0;32m----> 2\u001b[0m run_id\u001b[38;5;241m=\u001b[39m\u001b[43mrun\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masc\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'id'"
     ]
    }
   ],
   "source": [
    "run_steps = client.beta.threads.runs.steps.list(thread_id=thread.id, \n",
    "run_id=run.id, order=\"asc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at each Step's `step_details`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tool_calls': [{'id': 'call_WMNqd63PtX8vZzTwaA6eWpBg',\n",
       "   'code_interpreter': {'input': '# Python function to generate the first 20 Fibonacci numbers\\ndef fibonacci(n):\\n    fib_sequence = [0, 1]\\n    while len(fib_sequence) < n:\\n        fib_sequence.append(fib_sequence[-1] + fib_sequence[-2])\\n    return fib_sequence\\n\\n# Generate the first 20 Fibonacci numbers\\nfirst_20_fibonacci = fibonacci(20)\\nfirst_20_fibonacci',\n",
       "    'outputs': [{'logs': '[0,\\n 1,\\n 1,\\n 2,\\n 3,\\n 5,\\n 8,\\n 13,\\n 21,\\n 34,\\n 55,\\n 89,\\n 144,\\n 233,\\n 377,\\n 610,\\n 987,\\n 1597,\\n 2584,\\n 4181]',\n",
       "      'type': 'logs'}]},\n",
       "   'type': 'code_interpreter'}],\n",
       " 'type': 'tool_calls'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "null\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'message_creation': {'message_id': 'msg_z593lE5bvcD6BngeDFHDxzwm'},\n",
       " 'type': 'message_creation'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "null\n"
     ]
    }
   ],
   "source": [
    "for step in run_steps.data:\n",
    "    step_details = step.step_details\n",
    "    print(json.dumps(show_json(step_details), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the `step_details` for two Steps:\n",
    "\n",
    "1. `tool_calls` (plural, since it could be more than one in a single Step)\n",
    "2. `message_creation`\n",
    "\n",
    "The first Step is a `tool_calls`, specifically using the `code_interpreter` which contains:\n",
    "\n",
    "- `input`, which was the Python code generated before the tool was called, and\n",
    "- `output`, which was the result of running the Code Interpreter.\n",
    "\n",
    "The second Step is a `message_creation`, which contains the `message` that was added to the Thread to communicate the results to the user.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval\n",
    "\n",
    "Another powerful tool in the Assistants API is [Retrieval](https://platform.openai.com/docs/assistants/tools/knowledge-retrieval): the ability to upload files that the Assistant will use as a knowledge base when answering questions. This can also be enabled from the Dashboard or the API, where we can upload files we want to be used.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Enabling retrieval](../images/assistants_overview_enable_retrieval.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'asst_2Hfaqc71l3fu7pvbd1PkPrpf',\n",
       " 'created_at': 1711920054,\n",
       " 'description': None,\n",
       " 'file_ids': ['file-wGSa82c3EhDR2onbkT8GxVSR'],\n",
       " 'instructions': 'You are a personal math tutor. Answer questions briefly, in a sentence or less.',\n",
       " 'metadata': {},\n",
       " 'model': 'gpt-4-1106-preview',\n",
       " 'name': 'Math Tutor',\n",
       " 'object': 'assistant',\n",
       " 'tools': [{'type': 'code_interpreter'}, {'type': 'retrieval'}]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Upload the file\n",
    "file = client.files.create(\n",
    "    file=open(\n",
    "        \"data/language_models_are_unsupervised_multitask_learners.pdf\",\n",
    "        \"rb\",\n",
    "    ),\n",
    "    purpose=\"assistants\",\n",
    ")\n",
    "# Update Assistant\n",
    "assistant = client.beta.assistants.update(\n",
    "    MATH_ASSISTANT_ID,\n",
    "    tools=[{\"type\": \"code_interpreter\"}, {\"type\": \"retrieval\"}],\n",
    "    file_ids=[file.id],\n",
    ")\n",
    "show_json(assistant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "assistant > retrieval\n",
      "\n",
      "\n",
      "assistant > The ML paper discusses the use of a Transformer-based architecture leveraging a predictive model capable of generalizing from unordered tokens to structured patterns in data . It also mentions the Children's Book Test to evaluate the performance of language models on different categories of words, which provides insight into the mathematical modeling of language understanding and prediction of contextually relevant tokens ."
     ]
    }
   ],
   "source": [
    "thread, run = create_thread_and_run(\n",
    "    \"What are some cool math concepts behind this ML paper pdf? Explain in two sentences.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note**\n",
    "> There are more intricacies in Retrieval, like [Annotations](https://platform.openai.com/docs/assistants/how-it-works/managing-threads-and-messages), which may be covered in another cookbook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions\n",
    "\n",
    "As a final powerful tool for your Assistant, you can specify custom [Functions](https://platform.openai.com/docs/assistants/tools/function-calling) (much like the [Function Calling](https://platform.openai.com/docs/guides/function-calling) in the Chat Completions API). During a Run, the Assistant can then indicate it wants to call one or more functions you specified. You are then responsible for calling the Function, and providing the output back to the Assistant.\n",
    "\n",
    "Let's take a look at an example by defining a `display_quiz()` Function for our Math Tutor.\n",
    "\n",
    "This function will take a `title` and an array of `question`s, display the quiz, and get input from the user for each:\n",
    "\n",
    "- `title`\n",
    "- `questions`\n",
    "  - `question_text`\n",
    "  - `question_type`: [`MULTIPLE_CHOICE`, `FREE_RESPONSE`]\n",
    "  - `choices`: [\"choice 1\", \"choice 2\", ...]\n",
    "\n",
    "Unfortunately I don't know how to get user input within a Python Notebook, so I'll be mocking out responses with `get_mock_response...`. This is where you'd get the user's actual input.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mock_response_from_user_multiple_choice():\n",
    "    return \"a\"\n",
    "\n",
    "\n",
    "def get_mock_response_from_user_free_response():\n",
    "    return \"I don't know.\"\n",
    "\n",
    "\n",
    "def display_quiz(title, questions):\n",
    "    print(\"Quiz:\", title)\n",
    "    print()\n",
    "    responses = []\n",
    "\n",
    "    for q in questions:\n",
    "        print(q[\"question_text\"])\n",
    "        response = \"\"\n",
    "\n",
    "        # If multiple choice, print options\n",
    "        if q[\"question_type\"] == \"MULTIPLE_CHOICE\":\n",
    "            for i, choice in enumerate(q[\"choices\"]):\n",
    "                print(f\"{i}. {choice}\")\n",
    "            response = get_mock_response_from_user_multiple_choice()\n",
    "\n",
    "        # Otherwise, just get response\n",
    "        elif q[\"question_type\"] == \"FREE_RESPONSE\":\n",
    "            response = get_mock_response_from_user_free_response()\n",
    "\n",
    "        responses.append(response)\n",
    "        print()\n",
    "\n",
    "    return responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what a sample quiz would look like:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quiz: Sample Quiz\n",
      "\n",
      "What is your name?\n",
      "\n",
      "What is your favorite color?\n",
      "0. Red\n",
      "1. Blue\n",
      "2. Green\n",
      "3. Yellow\n",
      "\n",
      "Responses: [\"I don't know.\", 'a']\n"
     ]
    }
   ],
   "source": [
    "responses = display_quiz(\n",
    "    \"Sample Quiz\",\n",
    "    [\n",
    "        {\"question_text\": \"What is your name?\", \"question_type\": \"FREE_RESPONSE\"},\n",
    "        {\n",
    "            \"question_text\": \"What is your favorite color?\",\n",
    "            \"question_type\": \"MULTIPLE_CHOICE\",\n",
    "            \"choices\": [\"Red\", \"Blue\", \"Green\", \"Yellow\"],\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "print(\"Responses:\", responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's define the interface of this function in JSON format, so our Assistant can call it:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_json = {\n",
    "    \"name\": \"display_quiz\",\n",
    "    \"description\": \"Displays a quiz to the student, and returns the student's response. A single quiz can have multiple questions.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"title\": {\"type\": \"string\"},\n",
    "            \"questions\": {\n",
    "                \"type\": \"array\",\n",
    "                \"description\": \"An array of questions, each with a title and potentially options (if multiple choice).\",\n",
    "                \"items\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"question_text\": {\"type\": \"string\"},\n",
    "                        \"question_type\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"enum\": [\"MULTIPLE_CHOICE\", \"FREE_RESPONSE\"],\n",
    "                        },\n",
    "                        \"choices\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n",
    "                    },\n",
    "                    \"required\": [\"question_text\"],\n",
    "                },\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"title\", \"questions\"],\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, let's update our Assistant either through the Dashboard or the API.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Enabling custom function](../images/assistants_overview_enable_function.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note**\n",
    "> Pasting the function JSON into the Dashboard was a bit finicky due to indentation, etc. I just asked ChatGPT to format my function the same as one of the examples on the Dashboard :).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'asst_2Hfaqc71l3fu7pvbd1PkPrpf',\n",
       " 'created_at': 1711920054,\n",
       " 'description': None,\n",
       " 'file_ids': ['file-wGSa82c3EhDR2onbkT8GxVSR'],\n",
       " 'instructions': 'You are a personal math tutor. Answer questions briefly, in a sentence or less.',\n",
       " 'metadata': {},\n",
       " 'model': 'gpt-4-1106-preview',\n",
       " 'name': 'Math Tutor',\n",
       " 'object': 'assistant',\n",
       " 'tools': [{'type': 'code_interpreter'},\n",
       "  {'type': 'retrieval'},\n",
       "  {'function': {'name': 'display_quiz',\n",
       "    'description': \"Displays a quiz to the student, and returns the student's response. A single quiz can have multiple questions.\",\n",
       "    'parameters': {'type': 'object',\n",
       "     'properties': {'title': {'type': 'string'},\n",
       "      'questions': {'type': 'array',\n",
       "       'description': 'An array of questions, each with a title and potentially options (if multiple choice).',\n",
       "       'items': {'type': 'object',\n",
       "        'properties': {'question_text': {'type': 'string'},\n",
       "         'question_type': {'type': 'string',\n",
       "          'enum': ['MULTIPLE_CHOICE', 'FREE_RESPONSE']},\n",
       "         'choices': {'type': 'array', 'items': {'type': 'string'}}},\n",
       "        'required': ['question_text']}}},\n",
       "     'required': ['title', 'questions']}},\n",
       "   'type': 'function'}]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "assistant = client.beta.assistants.update(\n",
    "    MATH_ASSISTANT_ID,\n",
    "    tools=[\n",
    "        {\"type\": \"code_interpreter\"},\n",
    "        {\"type\": \"retrieval\"},\n",
    "        {\"type\": \"function\", \"function\": function_json},\n",
    "    ],\n",
    ")\n",
    "show_json(assistant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, we ask for a quiz.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "assistant > retrieval\n",
      "\n",
      "\n",
      "assistant > From the content of the provided document 'Language Models are Unsupervised Multitask Learners', we can formulate a quiz with one open-ended question and one multiple-choice question. \n",
      "\n",
      "Here are the drafted quiz questions:\n",
      "\n",
      "**Open-Ended Question:**\n",
      "What is the primary goal of advancing toward more general systems in the field of machine learning, according to the article?\n",
      "\n",
      "**Multiple-Choice Question:**\n",
      "Which one of the following tasks does the language model GPT-2 NOT achieve state of the art results in, according to a zero-shot setting in the document?\n",
      "- A) Reading Comprehension\n",
      "- B) Translation\n",
      "- C) Summarization\n",
      "- D) Language Modeling\n",
      "\n",
      "Let's use the quiz tool to present these questions to the student."
     ]
    }
   ],
   "source": [
    "thread, run = create_thread_and_run(\n",
    "    \"Make a quiz with 2 questions: One open ended, one multiple choice. Then, give me feedback for the responses.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, however, when we check the Run's `status` we see `requires_action`! Let's take a closer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'model_dump_json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mshow_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m, in \u001b[0;36mshow_json\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshow_json\u001b[39m(obj):\n\u001b[0;32m----> 4\u001b[0m     display(json\u001b[38;5;241m.\u001b[39mloads(\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_dump_json\u001b[49m()))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'model_dump_json'"
     ]
    }
   ],
   "source": [
    "show_json(run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `required_action` field indicates a Tool is waiting for us to run it and submit its output back to the Assistant. Specifically, the `display_quiz` function! Let's start by parsing the `name` and `arguments`.\n",
    "\n",
    "> **Note**\n",
    "> While in this case we know there is only one Tool call, in practice the Assistant may choose to call multiple tools.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'required_action'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Extract single tool call\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m tool_call \u001b[38;5;241m=\u001b[39m \u001b[43mrun\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequired_action\u001b[49m\u001b[38;5;241m.\u001b[39msubmit_tool_outputs\u001b[38;5;241m.\u001b[39mtool_calls[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      3\u001b[0m name \u001b[38;5;241m=\u001b[39m tool_call\u001b[38;5;241m.\u001b[39mfunction\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m      4\u001b[0m arguments \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(tool_call\u001b[38;5;241m.\u001b[39mfunction\u001b[38;5;241m.\u001b[39marguments)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'required_action'"
     ]
    }
   ],
   "source": [
    "# Extract single tool call\n",
    "tool_call = run.required_action.submit_tool_outputs.tool_calls[0]\n",
    "name = tool_call.function.name\n",
    "arguments = json.loads(tool_call.function.arguments)\n",
    "\n",
    "print(\"Function Name:\", name)\n",
    "print(\"Function Arguments:\")\n",
    "arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's actually call our `display_quiz` function with the arguments provided by the Assistant:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'arguments' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m responses \u001b[38;5;241m=\u001b[39m display_quiz(\u001b[43marguments\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m], arguments[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestions\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResponses:\u001b[39m\u001b[38;5;124m\"\u001b[39m, responses)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'arguments' is not defined"
     ]
    }
   ],
   "source": [
    "responses = display_quiz(arguments[\"title\"], arguments[\"questions\"])\n",
    "print(\"Responses:\", responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! (Remember these responses are the one's we mocked earlier. In reality, we'd be getting input from the back from this function call.)\n",
    "\n",
    "Now that we have our responses, let's submit them back to the Assistant. We'll need the `tool_call` ID, found in the `tool_call` we parsed out earlier. We'll also need to encode our `list`of responses into a `str`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'run_98PGE3qGtHoaWaCLoytyRUBf',\n",
       " 'assistant_id': 'asst_9HAjl9y41ufsViNcThW1EXUS',\n",
       " 'cancelled_at': None,\n",
       " 'completed_at': None,\n",
       " 'created_at': 1699828370,\n",
       " 'expires_at': 1699828970,\n",
       " 'failed_at': None,\n",
       " 'file_ids': ['file-MdXcQI8OdPp76wukWI4dpLwW'],\n",
       " 'instructions': 'You are a personal math tutor. Answer questions briefly, in a sentence or less.',\n",
       " 'last_error': None,\n",
       " 'metadata': {},\n",
       " 'model': 'gpt-4-1106-preview',\n",
       " 'object': 'thread.run',\n",
       " 'required_action': None,\n",
       " 'started_at': 1699828370,\n",
       " 'status': 'queued',\n",
       " 'thread_id': 'thread_bICTESFvWoRdj0O0SzsosLCS',\n",
       " 'tools': [{'type': 'code_interpreter'},\n",
       "  {'type': 'retrieval'},\n",
       "  {'function': {'name': 'display_quiz',\n",
       "    'parameters': {'type': 'object',\n",
       "     'properties': {'title': {'type': 'string'},\n",
       "      'questions': {'type': 'array',\n",
       "       'description': 'An array of questions, each with a title and potentially options (if multiple choice).',\n",
       "       'items': {'type': 'object',\n",
       "        'properties': {'question_text': {'type': 'string'},\n",
       "         'question_type': {'type': 'string',\n",
       "          'enum': ['MULTIPLE_CHOICE', 'FREE_RESPONSE']},\n",
       "         'choices': {'type': 'array', 'items': {'type': 'string'}}},\n",
       "        'required': ['question_text']}}},\n",
       "     'required': ['title', 'questions']},\n",
       "    'description': \"Displays a quiz to the student, and returns the student's response. A single quiz can have multiple questions.\"},\n",
       "   'type': 'function'}]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = client.beta.threads.runs.submit_tool_outputs(\n",
    "    thread_id=thread.id,\n",
    "    run_id=run.id,\n",
    "    tool_outputs=[\n",
    "        {\n",
    "            \"tool_call_id\": tool_call.id,\n",
    "            \"output\": json.dumps(responses),\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "show_json(run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now wait for the Run to complete once again, and check our Thread!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Messages\n",
      "user: Make a quiz with 2 questions: One open ended, one multiple choice. Then, give me feedback for the responses.\n",
      "assistant: Thank you for attempting the quiz.\n",
      "\n",
      "For the first question, it's important to know that the square root of a negative number is not a real number because real numbers consist of all the numbers on the number line, and that includes all positive numbers, zero, and negative numbers. However, the square root of a negative number is not on this number line; instead, it is what we call an imaginary number. When we want to take the square root of a negative number, we typically use the imaginary unit \\(i\\), where \\(i\\) is defined as \\(\\sqrt{-1}\\).\n",
      "\n",
      "For the second question, the correct answer is \"108 degrees.\" In a regular pentagon, which is a five-sided polygon with equal sides and angles, each interior angle is \\(108\\) degrees. This is because the sum of the interior angles of a pentagon is \\(540\\) degrees, and when divided by \\(5\\) (the number of angles), it gives \\(108\\) degrees per angle. The choice you selected, \"72 degrees,\" actually refers to the external angle of a regular pentagon, not the internal angle.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run = wait_on_run(run, thread)\n",
    "pretty_print(get_response(thread))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Woohoo 🎉\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "We covered a lot of ground in this notebook, give yourself a high-five! Hopefully you should now have a strong foundation to build powerful, stateful experiences with tools like Code Interpreter, Retrieval, and Functions!\n",
    "\n",
    "There's a few sections we didn't cover for the sake of brevity, so here's a few resources to explore further:\n",
    "\n",
    "- [Annotations](https://platform.openai.com/docs/assistants/how-it-works/managing-threads-and-messages): parsing file citations\n",
    "- [Files](https://platform.openai.com/docs/api-reference/assistants/file-object): Thread scoped vs Assistant scoped\n",
    "- [Parallel Function Calls](https://platform.openai.com/docs/guides/function-calling/parallel-function-calling): calling multiple tools in a single Step\n",
    "- Multi-Assistant Thread Runs: single Thread with Messages from multiple Assistants\n",
    "- Streaming: coming soon!\n",
    "\n",
    "Now go off and build something ama[zing](https://www.youtube.com/watch?v=xvFZjo5PgG0&pp=ygUQcmljayByb2xsIG5vIGFkcw%3D%3D)!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
